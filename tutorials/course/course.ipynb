{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pyflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyflow is a high-level language to describe suites. We aim to build object-oriented suites that are designed and maintained as software.\n",
    "\n",
    "Pyflow acts as a compiler and library for that language, that generates ecflow suites. Internally it wraps the ecflow python library.\n",
    "\n",
    "* Provides higher level API\n",
    "* Introduces common idioms, and provides helper functionality\n",
    "* Encourages the use of certain work practices\n",
    "* pyflow classes wrap ecFlow classes (pyflow.Family wraps ecflow.Family)\n",
    "\n",
    "An ecflow suite is made up of four elements:\n",
    "\n",
    "* A visual and executable structure - the definitions\n",
    "* A set of scripts\n",
    "* Any additional deployable resources (e.g. list of MARS requests)\n",
    "* A set of machine configurations on which to run scripts\n",
    "\n",
    "Pyflow provides interfaces to provide and control any or all of these components.\n",
    "\n",
    "***This course assumes a working knowledge of ecflow, and will not attempt to introduce ecflow concepts.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preconfiguration of notebook\n",
    "\n",
    "To make use of this course you will need:\n",
    "\n",
    " 1. An environment containing Python, ecflow and pyflow. \n",
    " 2. A local ecflow server, started using the eflow_start.sh script or using an existing ecflow server. Update the `server_host` and `server_port` values to those for your server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import pyflow as pf\n",
    "scratchdir = os.path.join(os.path.abspath(''), 'scratch')\n",
    "filesdir = os.path.join(scratchdir, 'files')\n",
    "outdir = os.path.join(scratchdir, 'out')\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "server_host = 'localhost'\n",
    "server_port = 2001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trivial Starting Example\n",
    "\n",
    "To get us started, consider a very simple starting suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('trivial',\n",
    "              host=pf.LocalHost('localhost'),\n",
    "              files=os.path.join(filesdir, 'trivial'),\n",
    "              home=outdir,\n",
    "              defstatus=pf.state.suspended) as s:\n",
    "    pf.Label('flag', '')\n",
    "    t1 = pf.Task('t1', script='echo \"I am on $(hostname) : $ECF_HOST\"')\n",
    "    t2 = pf.Task('t2', script='ecflow_client --alter=change label flag \"I am set\" /trivial')\n",
    "    t1 >> t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that ecflow is happy with everything, and see the definitions that will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite trivial\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/trivial'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  label flag \"\"\n",
      "  task t1\n",
      "  task t2\n",
      "    trigger t1 eq complete\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.check_definition()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the suite is a two-stage process, in which we generate any script files and then play the suite. These two processes are entirely independent.\n",
    "\n",
    "Taking the software analogy; the generation stage acts as a compilation phase, and the deployment as an installation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/trivial/t1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/trivial/t1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/trivial/t2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/trivial/t2.ecf\n"
     ]
    }
   ],
   "source": [
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idiomatic pyflow suites\n",
    "\n",
    "We aim to build object-oriented suites, which compile to ecflow output.\n",
    "\n",
    "Ecflow suites involve the construction of three tree-structures:\n",
    "\n",
    " 1. A graphical tree, visible to the user of the suite.\n",
    " 2. A Directed Graph for execution (not necessarily a DAG, as it may contain cycles).\n",
    " 3. An on-disk layout of scripts.\n",
    " \n",
    "The on-disk layout for scripts is constrained by ecflow and is discussed in the section on Scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Suites\n",
    "\n",
    "### Suite Structural Layout\n",
    "\n",
    "We encourage pyflow users to use the python `with` statement to build the structure of the suites following the graphical ecflow tree.\n",
    "\n",
    "Dependencies are then added to form the Directed Graph for execution.\n",
    "\n",
    "The example below creates an initial simple suite with interdependent tasks. In software terms it is essentially an example of *procedural programming*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite first_suite\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"default\"\n",
      "  family family1\n",
      "    task t1\n",
      "    task t2\n",
      "      trigger t1 eq complete\n",
      "      edit FOO 'bar'\n",
      "  endfamily\n",
      "  family family2\n",
      "    trigger family1 eq complete\n",
      "    task t1\n",
      "    task t2\n",
      "      trigger t1 eq complete\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('first_suite') as s:\n",
    "    \n",
    "    with pf.Family('family1') as f1:\n",
    "        t1 = pf.Task('t1')\n",
    "        with pf.Task('t2') as t2:\n",
    "            pf.Variable('FOO', 'bar')\n",
    "            \n",
    "        t1 >> t2\n",
    "        \n",
    "    with pf.Family('family2') as f2:\n",
    "        t1 = pf.Task('t1')\n",
    "        t2 = pf.Task('t2')\n",
    "        t1 >> t2\n",
    "        \n",
    "    f1 >> f2\n",
    "    \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Oriented Suites\n",
    "\n",
    "Whilst procedural programming can be used to build simple suites, to manage long-term lifecycles of complex suites we encourage drawing inspiration from object-oriented software development.\n",
    "\n",
    "Suites can be split into objects that are derived from pyflow components. Suites can then be assembled from those configurable and reusable objects.\n",
    "\n",
    "### Deriving From Task\n",
    "\n",
    "Probably the most important pyflow class to subclass is `pf.Task`. This object describes what should be carried out as one executable unit.\n",
    "\n",
    "Consider this ***non-object-oriented*** task definition built within a Family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  family f\n",
      "    task my_task\n",
      "      defstatus suspended\n",
      "      edit HALF '7'\n",
      "      edit LIMIT '14'\n",
      "      label a_label \"with a value\"\n",
      "  endfamily\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Family('f') as f:\n",
    "    \n",
    "    variables = {\n",
    "        'HALF': 7,\n",
    "        'LIMIT': 2*7\n",
    "    }\n",
    "        \n",
    "    labels = {\n",
    "        'a_label': 'with a value'\n",
    "    }\n",
    "    \n",
    "    t = pf.Task('my_task', labels=labels, defstatus=pf.state.suspended, **variables)\n",
    "    \n",
    "    # Note that t is incomplete at this point...\n",
    "    t.script = [\n",
    "        'echo \"This is a counting task ...\"',\n",
    "        'for i in $(seq 1 $HALF); do echo \"count $i/$LIMIT\"; done',\n",
    "        'i=$[$HALF+1]; while [ $i -lt $LIMIT ]; do echo \"count $i/$LIMIT\" ; i=$[$i+1]; done'\n",
    "    ]\n",
    "        \n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a suite grows, and the number of tasks increases, the complexity of managing all of these components becomes prohibitive.\n",
    "\n",
    "We wish to *encapsulate* all of the functionality related to this task into a single object. As we want to reuse functionality we organise objects into classes. These classes should be appropriately configurable.\n",
    "\n",
    "As the number of tasks increases, we can re-use the class to create objects with similar behaviour. This in turn will dramatically reduce the complexity of the Families and then of the Suites.\n",
    "\n",
    "The above task should now be defined as a reusable class, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite CountingSuite\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"default\"\n",
      "  family F\n",
      "    task Seven\n",
      "      defstatus suspended\n",
      "      edit HALF '7'\n",
      "      edit LIMIT '14'\n",
      "      label counter_label \"count to 14\"\n",
      "    task Five\n",
      "      edit HALF '5'\n",
      "      edit LIMIT '10'\n",
      "      label counter_label \"count to 10\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/Seven.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/Seven.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/Five.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/Five.ecf\n"
     ]
    }
   ],
   "source": [
    "class MyTask(pf.Task):\n",
    "    \n",
    "    \"\"\"Counts to the double of a number, first half using a for loop then a while loop\"\"\"\n",
    "    \n",
    "    def __init__(self, name, default_value=0, **kwargs):\n",
    "        \n",
    "        variables = {\n",
    "            'HALF': default_value,\n",
    "            'LIMIT': 2*default_value,\n",
    "        }\n",
    "        variables.update(**kwargs)\n",
    "        \n",
    "        labels = {\n",
    "            'counter_label': 'count to {}'.format(2*default_value)\n",
    "        }\n",
    "        \n",
    "        script = [\n",
    "            'echo \"This is a counting task named {}\"'.format(name),\n",
    "            'for i in $(seq 1 $HALF); do echo \"count $i/$LIMIT\"; done',\n",
    "            'i=$[$HALF+1]; while [ $i -lt $LIMIT ]; do echo \"count $i/$LIMIT\" ; i=$[$i+1]; done'\n",
    "        ]\n",
    "        \n",
    "        super().__init__(name,\n",
    "                         script=script,\n",
    "                         labels=labels,\n",
    "                         **variables)\n",
    "\n",
    "with pf.Suite('CountingSuite', files=os.path.join(filesdir, 'CountingSuite')) as s:\n",
    "    with pf.Family('F') as f:\n",
    "        MyTask('Seven', 7, defstatus=pf.state.suspended)\n",
    "        MyTask('Five', 5)\n",
    "    \n",
    "print(s)\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving from Family and other pyflow objects\n",
    "\n",
    "The same process can be used for deriving from Families or other pyflow-related classes. In this manner we can build up configurable functionality piece by piece.\n",
    "\n",
    "Note how the family takes an input parameter, `counters`, to control how many tasks it generates internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  family TaskCounter\n",
      "    label total_counters \"7\"\n",
      "    task TaskCounter_0\n",
      "      edit HALF '0'\n",
      "      edit LIMIT '0'\n",
      "      label counter_label \"count to 0\"\n",
      "    task TaskCounter_1\n",
      "      trigger TaskCounter_0 eq complete\n",
      "      edit HALF '1'\n",
      "      edit LIMIT '2'\n",
      "      label counter_label \"count to 2\"\n",
      "    task TaskCounter_2\n",
      "      trigger TaskCounter_1 eq complete\n",
      "      edit HALF '2'\n",
      "      edit LIMIT '4'\n",
      "      label counter_label \"count to 4\"\n",
      "    task TaskCounter_3\n",
      "      trigger TaskCounter_2 eq complete\n",
      "      edit HALF '3'\n",
      "      edit LIMIT '6'\n",
      "      label counter_label \"count to 6\"\n",
      "    task TaskCounter_4\n",
      "      trigger TaskCounter_3 eq complete\n",
      "      edit HALF '4'\n",
      "      edit LIMIT '8'\n",
      "      label counter_label \"count to 8\"\n",
      "    task TaskCounter_5\n",
      "      trigger TaskCounter_4 eq complete\n",
      "      edit HALF '5'\n",
      "      edit LIMIT '10'\n",
      "      label counter_label \"count to 10\"\n",
      "    task TaskCounter_6\n",
      "      trigger TaskCounter_5 eq complete\n",
      "      edit HALF '6'\n",
      "      edit LIMIT '12'\n",
      "      label counter_label \"count to 12\"\n",
      "  endfamily\n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_3.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_3.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_4.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_4.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_5.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_5.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_6.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/CountingSuite/TaskCounter_6.ecf\n"
     ]
    }
   ],
   "source": [
    "class MyFamily(pf.Family):\n",
    "    \n",
    "    def __init__(self, name, counters, **kwargs):\n",
    "        \n",
    "        labels = {\n",
    "            'total_counters': counters\n",
    "        }\n",
    "        \n",
    "        super().__init__(name, labels=labels, **kwargs)\n",
    "        \n",
    "        with self:\n",
    "            pf.sequence(MyTask('{}_{}'.format(name,i), i) for i in range(counters))\n",
    "         \n",
    "with pf.Suite('CountingSuite', files=os.path.join(filesdir, 'CountingSuite')) as s:\n",
    "    print(MyFamily('TaskCounter', 7))\n",
    "\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing Suites from Reusable Components\n",
    "\n",
    "All objects in the suite can be constructed and configured. It is worth noting that the derived class can be used within python `with` statements in the same way as the base classes. This allows us to set some values or defaults without *forcing* us to build the entire suite inside the constructor of a derived type.\n",
    "\n",
    "Here we define a CourseSuite class which we will use throughout this notebook to facilitate working with the notebook environment and the local ecflow server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite configurable_suite\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family fam1\n",
      "    label total_counters \"3\"\n",
      "    task fam1_0\n",
      "      edit HALF '0'\n",
      "      edit LIMIT '0'\n",
      "      label counter_label \"count to 0\"\n",
      "    task fam1_1\n",
      "      trigger fam1_0 eq complete\n",
      "      edit HALF '1'\n",
      "      edit LIMIT '2'\n",
      "      label counter_label \"count to 2\"\n",
      "    task fam1_2\n",
      "      trigger fam1_1 eq complete\n",
      "      edit HALF '2'\n",
      "      edit LIMIT '4'\n",
      "      label counter_label \"count to 4\"\n",
      "  endfamily\n",
      "  family fam2\n",
      "    label total_counters \"5\"\n",
      "    task fam2_0\n",
      "      edit HALF '0'\n",
      "      edit LIMIT '0'\n",
      "      label counter_label \"count to 0\"\n",
      "    task fam2_1\n",
      "      trigger fam2_0 eq complete\n",
      "      edit HALF '1'\n",
      "      edit LIMIT '2'\n",
      "      label counter_label \"count to 2\"\n",
      "    task fam2_2\n",
      "      trigger fam2_1 eq complete\n",
      "      edit HALF '2'\n",
      "      edit LIMIT '4'\n",
      "      label counter_label \"count to 4\"\n",
      "    task fam2_3\n",
      "      trigger fam2_2 eq complete\n",
      "      edit HALF '3'\n",
      "      edit LIMIT '6'\n",
      "      label counter_label \"count to 6\"\n",
      "    task fam2_4\n",
      "      trigger fam2_3 eq complete\n",
      "      edit HALF '4'\n",
      "      edit LIMIT '8'\n",
      "      label counter_label \"count to 8\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam1_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_3.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_3.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_4.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configurable_suite/fam2_4.ecf\n"
     ]
    }
   ],
   "source": [
    "class CourseSuite(pf.Suite):\n",
    "    \"\"\"\n",
    "    This CourseSuite object will be used throughout the course to provide sensible\n",
    "    defaults without verbosity\n",
    "    \"\"\"\n",
    "    def __init__(self, name, **kwargs):\n",
    "        \n",
    "        config = {\n",
    "            'host': pf.LocalHost('localhost'),\n",
    "            'files': os.path.join(filesdir, name),\n",
    "            'home': outdir,\n",
    "            'defstatus': pf.state.suspended\n",
    "        }\n",
    "        config.update(kwargs)\n",
    "        \n",
    "        super().__init__(name, **config)\n",
    "\n",
    "         \n",
    "with CourseSuite('configurable_suite') as s:\n",
    "    MyFamily('fam1', 3)\n",
    "    MyFamily('fam2', 5)\n",
    "    \n",
    "print(s)\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyflow aims to provide a library of commonly used abstract functionality, but suites should aim to build and collect classes of internally useful functionality which can be used to build a suite out of relevant objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Tasks for this Notebook\n",
    "\n",
    "We define here some useful Tasks that we use throughout this course, to build object-oriented suites. The details of how they work are covered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSetter(pf.Task):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Accepts a sequence of label-value tuples\n",
    "        \"\"\"\n",
    "        script = [\n",
    "            pf.TemplateScript(\n",
    "                'ecflow_client --alter=change label {{ LABEL.name }} \"{{ VALUE }}\" {{ LABEL.parent.fullname }}',\n",
    "                LABEL=label, VALUE=value\n",
    "            ) for label, value in args\n",
    "        ]\n",
    "        \n",
    "        name = kwargs.pop('name', 'set_labels')\n",
    "        super().__init__(name, script=script, **kwargs)\n",
    "        \n",
    "        \n",
    "class WaitSeconds(pf.Task):\n",
    "    def __init__(self, seconds, **kwargs):\n",
    "        name = kwargs.pop('name', 'wait_{}'.format(seconds))\n",
    "        super().__init__(name, script='sleep {}'.format(seconds), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurabilty of Suites, Families, Tasks, Hosts ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build such library of classes and objects so we can re-use these components (Tasks, Families, Suites) in different contexts. A given task class could be used in a research workflow and then reused in another operational workflow.\n",
    "\n",
    "However different contexts may require some differences in the suite execution. To ensure that we still have a concise, maintainable and easily checkable suite, we need to cater for those differences preferably in a single entity (as opposed to spreadout through the suite).\n",
    "\n",
    "To that aim, we introduce the use of a _configuration object_ that will handle the differences, and therefore interact and configure our objects under each different context.\n",
    "\n",
    "This results in suites that are _configurable_ for different use-cases and different contexts and build fundamentally different generated suites from the same components\n",
    "\n",
    "A configuration object can be constructed manually for different use cases or as a result of parsing configuration files. It can be used to:\n",
    "\n",
    " * Provide constants and data for specific cases, that will be needed in the suites.\n",
    " * Switch functionality on/off or modify it.\n",
    " * Configuration for hosts where to run the tasks.\n",
    " * Locations of and details of data to process.\n",
    " \n",
    "But most importantly, as objects, these configuration objects can be programmable in themselves (can include code). The suite components can delegate part of the suite definition to these _configurators_ and as such the structure of the suite can be determined by logic in the configuration object if necessary.\n",
    "\n",
    "***Delegation is preferred over conditional 'if' statements in the suite depending on configuration values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConfig:\n",
    "    \"\"\"This is a very contrived example showing delegation of behaviour to configuration\"\"\"\n",
    "    \n",
    "    def __init__(self, name, common_count=3, unit_count=4, integration_count=5):\n",
    "        self.name = name\n",
    "        self.common_count=common_count\n",
    "        self.unit_count = unit_count\n",
    "        self.integration_count = integration_count\n",
    "    \n",
    "    def build_unit_tests(self):\n",
    "        pass\n",
    "    \n",
    "    def build_integration_tests(self):\n",
    "        pass    \n",
    "    \n",
    "    \n",
    "class ProductionConfig(BaseConfig): \n",
    "    def build_integration_tests(self):\n",
    "        with pf.Family('integration') as f:\n",
    "            pf.sequence(MyTask('integration_{}'.format(i), 123*i) for i in range(self.integration_count))\n",
    "        return f\n",
    "            \n",
    "    \n",
    "class DevConfig(BaseConfig):\n",
    "    def build_unit_tests(self):\n",
    "        with pf.Family('unit') as f:\n",
    "            pf.sequence(MyTask('unit_{}'.format(i), 123*i) for i in range(self.unit_count))\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a common testing family that behaves (structurally) differently according to the configuration supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfiguredFamily(pf.Family):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config.name)\n",
    "        \n",
    "        with self:\n",
    "\n",
    "            # the static part of the suite, common to all suites of this type\n",
    "            \n",
    "            with pf.Family('common') as common:\n",
    "                pf.sequence(MyTask('common_{}'.format(i), 123*i) for i in range(5))\n",
    "\n",
    "            # the dynamic part of the suite, with hooks for the variability\n",
    "\n",
    "            test_families = [\n",
    "                config.build_unit_tests(),\n",
    "                config.build_integration_tests()\n",
    "            ]\n",
    "\n",
    "            # some other static of the suite\n",
    "\n",
    "            with pf.Family('cleanup') as cleanup:\n",
    "                MyTask('cleaner')\n",
    "            \n",
    "            # establish dependencies\n",
    "            \n",
    "            common >> cleanup\n",
    "            for f in test_families:\n",
    "                if f is not None:\n",
    "                    common >> f >> cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  family prod\n",
      "    family common\n",
      "      task common_0\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "      task common_1\n",
      "        trigger common_0 eq complete\n",
      "        edit HALF '123'\n",
      "        edit LIMIT '246'\n",
      "        label counter_label \"count to 246\"\n",
      "      task common_2\n",
      "        trigger common_1 eq complete\n",
      "        edit HALF '246'\n",
      "        edit LIMIT '492'\n",
      "        label counter_label \"count to 492\"\n",
      "      task common_3\n",
      "        trigger common_2 eq complete\n",
      "        edit HALF '369'\n",
      "        edit LIMIT '738'\n",
      "        label counter_label \"count to 738\"\n",
      "      task common_4\n",
      "        trigger common_3 eq complete\n",
      "        edit HALF '492'\n",
      "        edit LIMIT '984'\n",
      "        label counter_label \"count to 984\"\n",
      "    endfamily\n",
      "    family integration\n",
      "      trigger common eq complete\n",
      "      task integration_0\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "      task integration_1\n",
      "        trigger integration_0 eq complete\n",
      "        edit HALF '123'\n",
      "        edit LIMIT '246'\n",
      "        label counter_label \"count to 246\"\n",
      "      task integration_2\n",
      "        trigger integration_1 eq complete\n",
      "        edit HALF '246'\n",
      "        edit LIMIT '492'\n",
      "        label counter_label \"count to 492\"\n",
      "    endfamily\n",
      "    family cleanup\n",
      "      trigger common eq complete and integration eq complete\n",
      "      task cleaner\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "    endfamily\n",
      "  endfamily\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "  family dev\n",
      "    family common\n",
      "      task common_0\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "      task common_1\n",
      "        trigger common_0 eq complete\n",
      "        edit HALF '123'\n",
      "        edit LIMIT '246'\n",
      "        label counter_label \"count to 246\"\n",
      "      task common_2\n",
      "        trigger common_1 eq complete\n",
      "        edit HALF '246'\n",
      "        edit LIMIT '492'\n",
      "        label counter_label \"count to 492\"\n",
      "      task common_3\n",
      "        trigger common_2 eq complete\n",
      "        edit HALF '369'\n",
      "        edit LIMIT '738'\n",
      "        label counter_label \"count to 738\"\n",
      "      task common_4\n",
      "        trigger common_3 eq complete\n",
      "        edit HALF '492'\n",
      "        edit LIMIT '984'\n",
      "        label counter_label \"count to 984\"\n",
      "    endfamily\n",
      "    family unit\n",
      "      trigger common eq complete\n",
      "      task unit_0\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "      task unit_1\n",
      "        trigger unit_0 eq complete\n",
      "        edit HALF '123'\n",
      "        edit LIMIT '246'\n",
      "        label counter_label \"count to 246\"\n",
      "      task unit_2\n",
      "        trigger unit_1 eq complete\n",
      "        edit HALF '246'\n",
      "        edit LIMIT '492'\n",
      "        label counter_label \"count to 492\"\n",
      "      task unit_3\n",
      "        trigger unit_2 eq complete\n",
      "        edit HALF '369'\n",
      "        edit LIMIT '738'\n",
      "        label counter_label \"count to 738\"\n",
      "      task unit_4\n",
      "        trigger unit_3 eq complete\n",
      "        edit HALF '492'\n",
      "        edit LIMIT '984'\n",
      "        label counter_label \"count to 984\"\n",
      "      task unit_5\n",
      "        trigger unit_4 eq complete\n",
      "        edit HALF '615'\n",
      "        edit LIMIT '1230'\n",
      "        label counter_label \"count to 1230\"\n",
      "      task unit_6\n",
      "        trigger unit_5 eq complete\n",
      "        edit HALF '738'\n",
      "        edit LIMIT '1476'\n",
      "        label counter_label \"count to 1476\"\n",
      "      task unit_7\n",
      "        trigger unit_6 eq complete\n",
      "        edit HALF '861'\n",
      "        edit LIMIT '1722'\n",
      "        label counter_label \"count to 1722\"\n",
      "      task unit_8\n",
      "        trigger unit_7 eq complete\n",
      "        edit HALF '984'\n",
      "        edit LIMIT '1968'\n",
      "        label counter_label \"count to 1968\"\n",
      "      task unit_9\n",
      "        trigger unit_8 eq complete\n",
      "        edit HALF '1107'\n",
      "        edit LIMIT '2214'\n",
      "        label counter_label \"count to 2214\"\n",
      "      task unit_10\n",
      "        trigger unit_9 eq complete\n",
      "        edit HALF '1230'\n",
      "        edit LIMIT '2460'\n",
      "        label counter_label \"count to 2460\"\n",
      "      task unit_11\n",
      "        trigger unit_10 eq complete\n",
      "        edit HALF '1353'\n",
      "        edit LIMIT '2706'\n",
      "        label counter_label \"count to 2706\"\n",
      "      task unit_12\n",
      "        trigger unit_11 eq complete\n",
      "        edit HALF '1476'\n",
      "        edit LIMIT '2952'\n",
      "        label counter_label \"count to 2952\"\n",
      "      task unit_13\n",
      "        trigger unit_12 eq complete\n",
      "        edit HALF '1599'\n",
      "        edit LIMIT '3198'\n",
      "        label counter_label \"count to 3198\"\n",
      "      task unit_14\n",
      "        trigger unit_13 eq complete\n",
      "        edit HALF '1722'\n",
      "        edit LIMIT '3444'\n",
      "        label counter_label \"count to 3444\"\n",
      "      task unit_15\n",
      "        trigger unit_14 eq complete\n",
      "        edit HALF '1845'\n",
      "        edit LIMIT '3690'\n",
      "        label counter_label \"count to 3690\"\n",
      "      task unit_16\n",
      "        trigger unit_15 eq complete\n",
      "        edit HALF '1968'\n",
      "        edit LIMIT '3936'\n",
      "        label counter_label \"count to 3936\"\n",
      "      task unit_17\n",
      "        trigger unit_16 eq complete\n",
      "        edit HALF '2091'\n",
      "        edit LIMIT '4182'\n",
      "        label counter_label \"count to 4182\"\n",
      "      task unit_18\n",
      "        trigger unit_17 eq complete\n",
      "        edit HALF '2214'\n",
      "        edit LIMIT '4428'\n",
      "        label counter_label \"count to 4428\"\n",
      "      task unit_19\n",
      "        trigger unit_18 eq complete\n",
      "        edit HALF '2337'\n",
      "        edit LIMIT '4674'\n",
      "        label counter_label \"count to 4674\"\n",
      "      task unit_20\n",
      "        trigger unit_19 eq complete\n",
      "        edit HALF '2460'\n",
      "        edit LIMIT '4920'\n",
      "        label counter_label \"count to 4920\"\n",
      "      task unit_21\n",
      "        trigger unit_20 eq complete\n",
      "        edit HALF '2583'\n",
      "        edit LIMIT '5166'\n",
      "        label counter_label \"count to 5166\"\n",
      "      task unit_22\n",
      "        trigger unit_21 eq complete\n",
      "        edit HALF '2706'\n",
      "        edit LIMIT '5412'\n",
      "        label counter_label \"count to 5412\"\n",
      "      task unit_23\n",
      "        trigger unit_22 eq complete\n",
      "        edit HALF '2829'\n",
      "        edit LIMIT '5658'\n",
      "        label counter_label \"count to 5658\"\n",
      "      task unit_24\n",
      "        trigger unit_23 eq complete\n",
      "        edit HALF '2952'\n",
      "        edit LIMIT '5904'\n",
      "        label counter_label \"count to 5904\"\n",
      "    endfamily\n",
      "    family cleanup\n",
      "      trigger common eq complete and unit eq complete\n",
      "      task cleaner\n",
      "        edit HALF '0'\n",
      "        edit LIMIT '0'\n",
      "        label counter_label \"count to 0\"\n",
      "    endfamily\n",
      "  endfamily\n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_3.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_3.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_4.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_4.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/integration_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/cleaner.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/cleaner.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_3.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_3.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_4.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/common_4.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_0.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_0.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_1.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_1.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_2.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_3.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_3.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_4.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_4.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_5.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_5.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_6.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_6.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_7.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_7.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_8.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_8.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_9.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_9.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_10.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_10.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_11.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_11.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_12.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_12.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_13.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_13.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_14.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_14.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_15.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_15.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_16.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_16.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_17.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_17.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_18.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_18.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_19.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_19.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_20.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_20.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_21.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_21.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_22.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_22.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_23.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_23.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_24.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/unit_24.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/cleaner.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/configuration_example/cleaner.ecf\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('configuration_example') as s:\n",
    "    \n",
    "    ConfiguredFamily(ProductionConfig('prod', integration_count=3))\n",
    "    \n",
    "    ConfiguredFamily(DevConfig('dev', unit_count=25))\n",
    "\n",
    "print(s.prod)\n",
    "print('\\n------------------------------------\\n')\n",
    "print(s.dev)\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyflow Families and AnchorFamilies\n",
    "\n",
    "The Family class provides the fundamental visual block of pyflow. Families provide two distinct roles within suites:\n",
    "\n",
    " 1. Visually grouping related families/tasks\n",
    " 2. Logically grouping related families/tasks from an execution perspective\n",
    " \n",
    "Due to constraints imposed by the order in which ecflow searches for scripts within the configured `files` location, by default ***all*** tasks with the same name must share the same script located in the `files` directory (if scripts are deployed by pyflow, they will be deployed to this directory). This means that tasks with the same name must either be avoided, or written to have identical scripts, and is a significant constraint on encapsulation in object-oriented suite design.\n",
    "\n",
    "For simple agregation of tasks, it is encouraged to use `pf.Family` or derive from it.\n",
    "This provides minimal encapsulation of tasks, but not of scripts.\n",
    "All tasks with the same name will share the same script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite family_example\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/family_example'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family simple\n",
      "    label example \"\"\n",
      "    task set_labels\n",
      "  endfamily\n",
      "  family derived_family\n",
      "    label total_counters \"5\"\n",
      "    task derived_family_0\n",
      "      edit HALF '0'\n",
      "      edit LIMIT '0'\n",
      "      label counter_label \"count to 0\"\n",
      "    task derived_family_1\n",
      "      trigger derived_family_0 eq complete\n",
      "      edit HALF '1'\n",
      "      edit LIMIT '2'\n",
      "      label counter_label \"count to 2\"\n",
      "    task derived_family_2\n",
      "      trigger derived_family_1 eq complete\n",
      "      edit HALF '2'\n",
      "      edit LIMIT '4'\n",
      "      label counter_label \"count to 4\"\n",
      "    task derived_family_3\n",
      "      trigger derived_family_2 eq complete\n",
      "      edit HALF '3'\n",
      "      edit LIMIT '6'\n",
      "      label counter_label \"count to 6\"\n",
      "    task derived_family_4\n",
      "      trigger derived_family_3 eq complete\n",
      "      edit HALF '4'\n",
      "      edit LIMIT '8'\n",
      "      label counter_label \"count to 8\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('family_example') as s:\n",
    "    with pf.Family('simple', labels={'example': ''}) as f:\n",
    "        LabelSetter((f.example, 'example text'))\n",
    "    MyFamily('derived_family', 5)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex functionality containing groups of tasks that require encapsulation we encourage the use of `AnchorFamily`.\n",
    "\n",
    "The `AnchorFamily` class updates the `files` location according to the relative path of the family from the suite (or previous `AnchorFamily`). Within an `AnchorFamily`, all script lookups are relative to this new location, providing isolation and encapsulation.\n",
    "\n",
    "All tasks with the same name *within an `AnchorFamily`* **must share the same script** located in the `files` location *for that `AnchorFamily`*.\n",
    "\n",
    "As such it is encouraged to:\n",
    " * Use `AnchorFamily` to encapsulate independent units within a suite. Typically these are the subtrees that make sense to deploy as a whole.\n",
    " * Use `Family` to aggregate tasks that could share scripts with each other. This can be within an `AnchorFamily`.\n",
    "\n",
    "The following example shows a suite with identical task names using different scripts, by scoping them with the `AnchorFamily`. These scripts are located and managed externally to the suite (in the `course` folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CourseSuite('anchor_families', files=os.path.join(os.path.abspath(''), 'anchor_families')) as s:\n",
    "    with pf.Family('f1'):\n",
    "        pf.Task('test1')        # Script <files>/test1.ecf\n",
    "    with pf.Family('f2'):\n",
    "        pf.Task('test1')        # Script <files>/test1.ecf\n",
    "    with pf.AnchorFamily('f'):\n",
    "        with pf.Family('f1'):\n",
    "            pf.Task('test1')    # Script <files>/f/test1.ecf\n",
    "            pf.Task('test2')    # Script <files>/f/test2.ecf\n",
    "        with pf.Family('f2'):\n",
    "            pf.Task('test2')    # Script <files>/f/test2.ecf\n",
    "            \n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This supports 2 ways of attaching scripts to identical `Tasks` with different parameters:\n",
    "\n",
    " * Generate one script per task containing the parameters\n",
    " * Use one script that is parameterised by the `Variables` on the `Families` and `Tasks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layout of suites in repository\n",
    "\n",
    "Object-oriented suites imply a certain breakdown of suites into components. These classes should be placed into different files within a repository.\n",
    "\n",
    "Sub components of suites should be placed in their own python submodule.\n",
    "\n",
    "We encourage maintaining Configurations independently to the suite structure.\n",
    "\n",
    "As an example, we have (part of) the filesystem layout for the MARS testing suites:\n",
    "\n",
    "```\n",
    "repo/\n",
    " ├─ configuration/\n",
    " │   ├─ marsdev.yaml\n",
    " │   ├─ fdb-server-dev.yaml\n",
    " │   └─ ...\n",
    " │  \n",
    " ├─ server/\n",
    " │   ├─ deployment/\n",
    " │   │   ├─ scripts/\n",
    " │   │   │   ├─ configure.sh\n",
    " │   │   │   ├─ build.sh\n",
    " │   │   │   └─ ...\n",
    " │   │   ├─ __init__.py\n",
    " │   │   ├─ deployment_family.py\n",
    " │   │   ├─ config.py\n",
    " │   │   └─ ...\n",
    " │   │  \n",
    " │   ├─ tests/\n",
    " │   │   ├─ fdb-tools/\n",
    " │   │   │   ├─ scripts/\n",
    " │   │   │   │   ├─ write/\n",
    " │   │   │   │   │   ├─ simple.sh\n",
    " │   │   │   │   │   ├─ masking.sh\n",
    " │   │   │   │   │   └─ ...\n",
    " │   │   │   │   └─ ...\n",
    " │   │   │   │\n",
    " │   │   │   ├─ __init__.py\n",
    " │   │   │   ├─ tools_family.py\n",
    " │   │   │   ├─ fdb_write.py\n",
    " │   │   │   ├─ fdb_wipe.py\n",
    " │   │   │   └─ ...\n",
    " │   │   └─ ... \n",
    " │   │\n",
    " │   ├─ __init__.py\n",
    " │   ├─ server_family.py\n",
    " │   └─ ...\n",
    " │   \n",
    " ├─ client/\n",
    " │   └─ ...\n",
    " │ \n",
    " ├─ mars_flow.py\n",
    " └─ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked Example: Building a Configurable, Object-Oriented Suite\n",
    "\n",
    "In this section we construct of a component of a test suite which will obtain testing data from MARS, perform some \"test\" on it, and then clean up after itself. This demonstrates a number of characteristics of object-oriented suite design:\n",
    "\n",
    " 1. Functionality that is configurable on a data description.\n",
    " 2. Functionality that is encapsulated in re-usable subcomponents\n",
    " 3. Delegation or inheritance to fine-tune behaviour within an existing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we create a helper class that can understand MARS requests, and output them in a useful format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarsRequest:\n",
    "    \n",
    "    separator = \",\\n    \"\n",
    "    \n",
    "    def __init__(self, verb, request_dict):\n",
    "        self._verb = verb\n",
    "        self._request_dict = request_dict\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            self._verb +\n",
    "            self.separator +            \n",
    "            self.separator.join(\"{}={}\".format(k, self._resolve(v)) for k, v in self._request_dict.items())\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def _resolve(v):\n",
    "        '''Convert values into something understood by MARS'''\n",
    "        if isinstance(v, bool):\n",
    "            return \"on\" if v else \"off\"\n",
    "        if isinstance(v, list):\n",
    "            return '/'.join(MarsRequest._resolve(vv) for vv in v)\n",
    "        if isinstance(v, str) and ('/' in v or '$' in v):\n",
    "            return '\"{}\"'.format(v)\n",
    "        return str(v)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requests are useful in the context of a MarsTask. This makes use of the MarsRequest object defined above to do something in the current working directory. It also creates a label for monitoring in ecflow and a timers file for diagnostics according to the environment variables understood by MARS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_task_script = \"\"\"\n",
    "req=$(mktemp req.XXXX)\n",
    "cat > $req <<@\n",
    "{{ REQUEST }}\n",
    "@\n",
    "mars $req\n",
    "rm $req\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MarsTask(pf.Task):\n",
    "    \n",
    "    verb = None\n",
    "    \n",
    "    def __init__(self, request_dict, **kwargs):\n",
    "        \n",
    "        # Construct a MarsRequest object from the dictionary supplied\n",
    "        assert self.verb is not None\n",
    "        request = MarsRequest(self.verb, request_dict)\n",
    "        \n",
    "        name = kwargs.get('name', \"{}_data\".format(self.verb))\n",
    "        \n",
    "        super().__init__(name,\n",
    "                         labels={'info': ''},\n",
    "                         script=pf.TemplateScript(mars_task_script, REQUEST=request),\n",
    "                         **kwargs)\n",
    "        \n",
    "        self.script.define_environment_variable('MARS_ECFLOW_LABEL', self.info)\n",
    "        self.script.define_environment_variable('MARS_TIMERS_FILE', \"{}.timers\".format(name))\n",
    "        \n",
    "        \n",
    "class ArchiveTask(MarsTask):\n",
    "    verb = 'archive'\n",
    "    \n",
    "class RetrieveTask(MarsTask):\n",
    "    verb = 'retrieve'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two major object-oriented approaches to making encapsulated: inheritance and delegation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suite Objects using Inheritance\n",
    "\n",
    "In this first example we are going to choose to use *inheritance*, although this is a fairly arbitrary choice. Which is desirable depends very much on context. We are also going to avoid using the `ArchiveTask` defined above just to avoid having to put lots of safety-related code into these examples.\n",
    "\n",
    "We wish to define a standard test pattern. This will:\n",
    "\n",
    " 1. create a temporary (scratch) directory within the scratch space configured for the given host.\n",
    " 2. Retrieve testing data, which is specified by the derived class\n",
    " 3. Run a test, which is defined by the derived class\n",
    " 4. Clean up after ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleanup(pf.Task):\n",
    "    def __init__(self, path, name='cleanup', **kwargs):\n",
    "        assert path != \"/\"\n",
    "        super().__init__(name, script='rm -rf \"{}\"'.format(path), **kwargs)\n",
    "      \n",
    "    \n",
    "class TestBase(pf.AnchorFamily):\n",
    "    \n",
    "    \"\"\"This class is an interface\"\"\"\n",
    "    \n",
    "    def __init__(self, name, **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        \n",
    "        # Generate a unique working directory\n",
    "        self._workdir = os.path.join(scratchdir,\n",
    "                                     self.suite.name, self.fullname.replace('/', '_'))\n",
    "        \n",
    "        # Ensure that the data gets put somewhere\n",
    "        self._data_filename = 'retrieved.grib'\n",
    "        request = self.request_dict().copy()\n",
    "        request['target'] = self._data_filename\n",
    "        \n",
    "        with self:\n",
    "            (\n",
    "                RetrieveTask(request, workdir=self._workdir)\n",
    "                >>\n",
    "                self.build_test()\n",
    "                >>\n",
    "                Cleanup(self._workdir)\n",
    "            )\n",
    "            \n",
    "    def request_dict(self):\n",
    "        raise NotImplementedError(\"abstract base property\")\n",
    "        \n",
    "    def build_test(self):\n",
    "        raise NotImplementedError(\"abstract base method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes should be derived from this abstract base test class, implementing the `request_dict` property and `build_test` methods. These derived classes can be further derived, or set up according to configuration passed in from outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GribLsTest(TestBase):\n",
    "    def __init__(self, date, param, **kwargs):\n",
    "        self._date = date\n",
    "        self._param = param\n",
    "        name = kwargs.pop('name', 'grib_ls')\n",
    "        super().__init__(name, **kwargs)\n",
    "        \n",
    "    def request_dict(self):\n",
    "        return {\n",
    "            'class': 'od',\n",
    "            'expver': '0001',\n",
    "            'stream': 'oper',\n",
    "            'date': self._date,\n",
    "            'time': [0, 12],\n",
    "            'step': 0,\n",
    "            'type': 'an',\n",
    "            'levtype': 'ml',\n",
    "            'levelist': 1,\n",
    "            'param': self._param,\n",
    "        }\n",
    "    \n",
    "    def build_test(self):\n",
    "        return pf.Task('grib_ls', workdir=self._workdir, script='grib_ls -m {}'.format(self._data_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LsTest(TestBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__('ls', **kwargs)\n",
    "        \n",
    "    def request_dict(self):\n",
    "        return {\n",
    "            'class': 'od',\n",
    "            'expver': '0001',\n",
    "            'stream': 'oper',\n",
    "            'date': -1,\n",
    "            'time': [0, 12],\n",
    "            'step': 0,\n",
    "            'type': 'an',\n",
    "            'levtype': 'ml',\n",
    "            'levelist': 1,\n",
    "            'param': 't',\n",
    "        }\n",
    "    \n",
    "    def build_test(self):\n",
    "        with pf.Family('test_family') as f:\n",
    "            pf.Task('ls', workdir=self._workdir, script='ls -l {}'.format(self._data_filename))\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tests can be combined inside a suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/grib_ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/grib_ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls/cleanup.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/grib_ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/grib_ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/grib_ls_2/cleanup.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/inheritance_example/tests/ls/cleanup.ecf\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('inheritance_example') as s:\n",
    "    with pf.Family('tests'):\n",
    "        (\n",
    "            GribLsTest(datetime.date.today() - datetime.timedelta(days=2), 't')\n",
    "            >>\n",
    "            GribLsTest(datetime.date.today() - datetime.timedelta(days=1), 'z', name='grib_ls_2')\n",
    "            >>\n",
    "            LsTest()\n",
    "        )\n",
    "    \n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suite Objects using Delegation\n",
    "\n",
    "Alternatively, we can take the approach of delegation such that decisions about the data request to use and the test to construct are delegated to a configuration object that is injected from the controlling scope. If we do this then the resultant `Test` class is now a concrete class (and we no longer need to derive from it), changing the structure of the suite somewhat.\n",
    "\n",
    "In this case, we build our Test class to delegate the construction to a config object whose type is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelegatingTest(pf.AnchorFamily):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        \n",
    "        name = config.name\n",
    "        super().__init__(name, **kwargs)\n",
    "        \n",
    "        # Generate a unique working directory\n",
    "        workdir = os.path.join(scratchdir,\n",
    "                               self.suite.name, self.fullname.replace('/', '_'))\n",
    "        \n",
    "        # Ensure that the data gets put somewhere\n",
    "        data_filename = 'retrieved.grib'\n",
    "        request = config.request_dict.copy()\n",
    "        request['target'] = data_filename\n",
    "        \n",
    "        with self:\n",
    "            (\n",
    "                RetrieveTask(request, workdir=workdir)\n",
    "                >>\n",
    "                config.build_test(workdir, data_filename)\n",
    "                >>\n",
    "                Cleanup(workdir)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create config classes that provide this functionality. They do not have to be built in the same way, or related to each other in any way other than that they provide the given functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LsConfig:\n",
    "    name = 'ls'\n",
    "    request_dict = {\n",
    "        'class': 'od',\n",
    "        'expver': '0001',\n",
    "        'stream': 'oper',\n",
    "        'date': -1,\n",
    "        'time': [0, 12],\n",
    "        'step': 0,\n",
    "        'type': 'an',\n",
    "        'levtype': 'ml',\n",
    "        'levelist': 1,\n",
    "        'param': 't',\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_test(workdir, data_filename):\n",
    "        with pf.Family('test_family') as f:\n",
    "            return pf.Task('ls', workdir=workdir, script='ls -l {}'.format(data_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GribLsConfig:\n",
    "    \n",
    "    def __init__(self, date, param, name='grib_ls'):\n",
    "        self.name = name\n",
    "        self._date = date\n",
    "        self._param = param\n",
    "        \n",
    "    @property\n",
    "    def request_dict(self):\n",
    "        return {\n",
    "            'class': 'od',\n",
    "            'expver': '0001',\n",
    "            'stream': 'oper',\n",
    "            'date': self._date,\n",
    "            'time': [0, 12],\n",
    "            'step': 0,\n",
    "            'type': 'an',\n",
    "            'levtype': 'ml',\n",
    "            'levelist': 1,\n",
    "            'param': self._param,\n",
    "        }\n",
    "    \n",
    "    def build_test(self, workdir, data_filename):\n",
    "        return pf.Task('grib_ls', workdir=workdir, script='grib_ls -m {}'.format(data_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then construct a combined configuration object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConfig:\n",
    "    def __init__(self):\n",
    "        self.tests = [\n",
    "            GribLsConfig(datetime.date.today() - datetime.timedelta(days=2), 't'),\n",
    "            GribLsConfig(datetime.date.today() - datetime.timedelta(days=1), 'z', name='grib_ls_2'),\n",
    "            LsConfig # n.b. here we just used a raw class.\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we then configure the suite with the config object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/grib_ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/grib_ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls/cleanup.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/grib_ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/grib_ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/grib_ls_2/cleanup.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/retrieve_data.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/retrieve_data.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/ls.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/ls.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/cleanup.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/delegated_example/ls/cleanup.ecf\n"
     ]
    }
   ],
   "source": [
    "class DelegatedSuite(CourseSuite):\n",
    "    def __init__(self, config):\n",
    "        super().__init__('delegated_example')\n",
    "        \n",
    "        with self:\n",
    "            pf.sequence(DelegatingTest(test_cfg) for test_cfg in config.tests)\n",
    "            \n",
    "s = DelegatedSuite(CombinedConfig())\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes on Suites, Families and Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Attributes - All Methods\n",
    "\n",
    "Typically, we have three methods to construct Attributes (or sub nodes) attached to any specific node. We give here examples both within a simple tree formulation of a suite, or within a class derived from a specific pyflow class.\n",
    "\n",
    "These different methods have different constraints on them, and differ in clarity and legibility in different contexts. Ultimately, the choic of which to use should come down to which is most legible in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can construct the pyflow object within a context manager containing the parent node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite s\n",
      "  family f\n",
      "    edit V 'value'\n",
      "    label l \"text\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s', host=pf.NullHost()) as s:\n",
    "    with pf.Family('f') as f:\n",
    "        pf.Label('l', 'text')\n",
    "        pf.Variable('V', 'value')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite s\n",
      "  family f\n",
      "    edit V 'value'\n",
      "    label l \"text\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DerivedFamily(pf.Family):\n",
    "    def __init__(self):\n",
    "        super().__init__('f')\n",
    "        with self:\n",
    "            pf.Label('l', 'text')\n",
    "            pf.Variable('V', 'value')\n",
    "\n",
    "with pf.Suite('s', host=pf.NullHost()) as s:\n",
    "    DerivedFamily()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, objects can be allocated by using keyword arguments on the parent node constructor. These take three forms:\n",
    "\n",
    " 1. For an attribute of which there can only be one instance, the keyword argument is the lower-case string of the attribute class name. E.g. \"script=\".\n",
    " 2. For an attribute of which there cane be multiple instances, the keyword argument is the lower-case, pluralised version of the class name. E.g. \"labels=\", and accepts a list or tuple.\n",
    " 3. Ecflow variables are passed in as direct keyword arguments, identified by being capitalised and valid ecflow variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite s\n",
      "  family f\n",
      "    edit V 'value'\n",
      "    label l \"text\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s', host=pf.NullHost()) as s:\n",
    "    pf.Family('f', labels={'l': 'text'}, V='value')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite s\n",
      "  family f\n",
      "    edit V 'value'\n",
      "    label l \"text\"\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DerivedFamily(pf.Family):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        variables = {'V': 'value'}\n",
    "        variables.update(kwargs)\n",
    "        \n",
    "        labels = {'l': 'text'}\n",
    "        \n",
    "        super().__init__('f', labels=labels, **variables)\n",
    "\n",
    "with pf.Suite('s', host=pf.NullHost()) as s:\n",
    "    DerivedFamily()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, unambiguously named pyflow objects (variables, script, ...) can be directly assigned to their parent nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite s\n",
      "  family f\n",
      "    edit V 'value'\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s', host=pf.NullHost()) as s:\n",
    "    f = pf.Family('f')\n",
    "    f.V = 'value' \n",
    "        \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice for Variables and Attributes\n",
    "\n",
    "Best practice for pyflow is to create derived types that encapsulate all of the concerns of a given class. This means that variable and attribute creation should occur within the constructor of the class being written. This should generally take the form of a setup section, in which various children are defined, before passing them through to the constructor of the superclass. Any structural children should then be defined below.\n",
    "\n",
    "**NOTE: Explain where/why super() should be called with respect to validity of 'self'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleFamily(pf.Family):\n",
    "    def __init__(self, name, example_value, initial_label, **kwargs):\n",
    "        \n",
    "        # This structure allows the kwargs to override any of these variables if needed, or\n",
    "        # to set other more general properties of the superclass (such as host=). The same\n",
    "        # effect could be achieved by using kwargs.setdefault(...) and passing kwargs through.\n",
    "        variables = {\n",
    "            'REQUIRED_VARIABLE': 'required_value',\n",
    "            'EXAMPLE_VARIABLE': example_value\n",
    "        }\n",
    "        variables.update(kwargs)\n",
    "        \n",
    "        labels = {\n",
    "            'a_label': initial_label\n",
    "        }\n",
    "        \n",
    "        super().__init__(name, labels=labels, **variables)\n",
    "        \n",
    "        # Here we define structural children\n",
    "        with self:\n",
    "            (\n",
    "                MyFamily('f1')\n",
    "                >>\n",
    "                MyTask('t1')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable substitition and expansion\n",
    "\n",
    "Variables and attributes can be directly referred to in scripts by making use of automatically exported environment variables of the same name. For example, a `RepeatDate('YMD', ...)` object may be referred to in a script by writing `$YMD`. This will be automatically detected by pyflow and the variable exported.\n",
    "\n",
    "If generating scripts, or using the templating engine, pyflow objects can generate their own representations. The `str()` and `repr()` functions in python will return representations of variables that can be used in scripts (after automatic variable exporting) and in technical contexts (pre variable exporting, such as in other ecflow variables) respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the properties of an ecflow `Variable` programatically. This allows us to make interdependencies explicit, and to generate snippets within scripts that are guaranteed to correctly use the objcets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$A_VARIABLE %A_VARIABLE% 1234\n",
      "A_VARIABLE /s:A_VARIABLE\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s'):\n",
    "    v = pf.Variable('A_VARIABLE', 1234)\n",
    "    \n",
    "print(str(v), repr(v), v.value)\n",
    "print(v.name, v.fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to automatically generate the correct shell-expansion of variables in the appropriate script context. Note that both python string substitution and Jinja2 templating use the `str()` representation by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo \"Variable value: $A_VARIABLE\"\n"
     ]
    }
   ],
   "source": [
    "text_script = 'echo \"Variable value: {}\"'.format(v)\n",
    "print(text_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo \"variable A_VARIABLE has value $A_VARIABLE\"\n"
     ]
    }
   ],
   "source": [
    "templated_script = pf.TemplateScript(\n",
    "    'echo \"variable {{ VARIABLE.name }} has value {{ VARIABLE }}\"',\n",
    "    VARIABLE=v\n",
    ")\n",
    "print(templated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ecflow objects that set accessible values can be accessed in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo \"The current date object is YMD. Value=$YMD\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s') as s:\n",
    "    pf.RepeatDate(\"YMD\", datetime.date(2019, 1, 1), datetime.date(2019, 12, 31))\n",
    "    \n",
    "print(pf.TemplateScript(\n",
    "    'echo \"The current date object is {{ YMD.name }}. Value={{ YMD }}',\n",
    "    YMD=s.YMD\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use templating to facilitate accessing attributes using the `ecflow_client`, and to correctly set thew according to mutable values (including ecflow variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecflow_client --alter=change label label \"$FOO\" /s\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s', FOO='bar') as s:\n",
    "    pf.Label('label', '')\n",
    "    \n",
    "print(pf.TemplateScript(\n",
    "    'ecflow_client --alter=change label {{ LABEL.name }} \"{{ VALUE }}\" {{ LABEL.parent.fullname }}',\n",
    "    LABEL=s.label,\n",
    "    VALUE=s.FOO\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using attributes belonging to other nodes\n",
    "\n",
    "Attributes associated with other nodes can be used by passing the relevant attribute object to the site where it is needed. This can be facilitated by accessing children of various nodes as attributes of the parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecflow_client --alter=change label the_label \"a value\" /s/family1\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s') as s:\n",
    "    with pf.Family('family1') as f1:\n",
    "        pf.Label('the_label', '')\n",
    "        \n",
    "    with pf.Family('family2') as f2:\n",
    "        LabelSetter((f1.the_label, \"a value\"), name='labeller')\n",
    "        \n",
    "print(f2.labeller.script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contexts where the relative path between nodes and attributes is required, the `relative_path` method is able to interrogate the relationships. Alternatively the `fullname` attribute will give the absolute path of nodes.\n",
    "\n",
    "Within pyflow expressions it should not be necessary to generate these paths manually, as the expression generator should do the right thing. However, it is sometimes useful to refer to these components within scripts, especially as expansions within templates scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family1:the_label\n",
      "family2/labeller\n",
      "../family2/labeller\n",
      "/s/family2/labeller\n",
      "/s/family1:the_label\n",
      "\n",
      "script: \n",
      " location of external node: /s/family2/labeller\n",
      "\n",
      "script: \n",
      " attribute relative path: ../family1:the_label\n"
     ]
    }
   ],
   "source": [
    "print(s.family1.the_label.relative_path(s.family2))\n",
    "print(s.family2.labeller.relative_path(s.family1))\n",
    "print(s.family2.labeller.relative_path(s.family1.the_label))\n",
    "print(s.family2.labeller.fullname)\n",
    "print(s.family1.the_label.fullname)\n",
    "\n",
    "print('\\nscript: \\n', pf.TemplateScript(\n",
    "    'location of external node: {{ NODE.fullname }}',\n",
    "    NODE=s.family2.labeller\n",
    "))\n",
    "print('\\nscript: \\n', pf.TemplateScript(\n",
    "    'attribute relative path: {{ ATTRIBUTE.relative_path(NODE) }}',\n",
    "    ATTRIBUTE=s.family1.the_label,\n",
    "    NODE=s.family2.labeller\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using variables defined in parents\n",
    "\n",
    "Ecflow suites inherit variables from above. If a task is making use of these variables it is very easy to end up writing tasks that assume the existence of variables in a suite already, without anything programattically indicating or enforcing that this relationship exists.\n",
    "\n",
    "Derived Tasks that make use of external variables should require that they be passed in from outside. If they are not directly used (i.e. the value is used in the script directly) then validity should be `asserted` in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite assert_external_variable\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/assert_external_variable'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family containing_family\n",
      "    edit EXTERNAL_VAR '1234'\n",
      "    task uses_var\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "script:\n",
      " echo \"external variable: $EXTERNAL_VAR\" \n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/assert_external_variable/uses_var.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/assert_external_variable/uses_var.ecf\n"
     ]
    }
   ],
   "source": [
    "class ChildTask(pf.Task):\n",
    "    def __init__(self, external_variable):\n",
    "        \n",
    "        assert external_variable.name == 'EXTERNAL_VAR'\n",
    "        script = 'echo \"external variable: $EXTERNAL_VAR\"'\n",
    "        super().__init__('uses_var', script=script)\n",
    "        \n",
    "with CourseSuite('assert_external_variable') as s:\n",
    "    with pf.Family('containing_family', EXTERNAL_VAR=1234) as f:\n",
    "        ChildTask(f.EXTERNAL_VAR)\n",
    "        \n",
    "print(s)\n",
    "print(\"script:\\n\", f.uses_var.script, '\\n')\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If scripts are being generated or templated, then the existence of inherited variables can be enforced through generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite templated_external_variable\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/templated_external_variable'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family containing_family\n",
      "    edit MY_VAR '1234'\n",
      "    task uses_var\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "script:\n",
      " echo \"external variable: $MY_VAR\" \n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/templated_external_variable/uses_var.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/templated_external_variable/uses_var.ecf\n"
     ]
    }
   ],
   "source": [
    "class ChildTask(pf.Task):\n",
    "    def __init__(self, external_variable):\n",
    "        script = pf.TemplateScript(\n",
    "            'echo \"external variable: {{ VARIABLE }}\"',\n",
    "            VARIABLE=external_variable\n",
    "        )\n",
    "        super().__init__('uses_var', script=script)\n",
    "        \n",
    "with CourseSuite('templated_external_variable') as s:\n",
    "    with pf.Family('containing_family', MY_VAR=1234) as f:\n",
    "        ChildTask(f.MY_VAR)\n",
    "        \n",
    "print(s)\n",
    "print(\"script:\\n\", f.uses_var.script, '\\n')\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can provide default values which are overridden in the context of an externally supplied variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite internal_or_external_variable\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family containing_family\n",
      "    edit MY_VAR '1234'\n",
      "    task external_variable\n",
      "    task external_value\n",
      "      edit TASK_VALUE '1234'\n",
      "    task default_value\n",
      "      edit TASK_VALUE '1234'\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "script external:\n",
      " echo \"external variable: $MY_VAR\" \n",
      "\n",
      "script default:\n",
      " echo \"external variable: $TASK_VALUE\" \n",
      "\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/external_variable.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/external_variable.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/external_value.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/external_value.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/default_value.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/internal_or_external_variable/default_value.ecf\n"
     ]
    }
   ],
   "source": [
    "class TaskWithVariable(pf.Task):\n",
    "    def __init__(self, name, default_value=1234, **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        \n",
    "        # Note that this sort of introspective setup is one that requires constructing\n",
    "        # components after calling the superclass\n",
    "        if isinstance(default_value, pf.Variable):\n",
    "            var = default_value\n",
    "        else:\n",
    "            self.TASK_VALUE = default_value\n",
    "            var = self.TASK_VALUE\n",
    "        \n",
    "        self.script = pf.TemplateScript(\n",
    "            'echo \"external variable: {{ VARIABLE }}\"',\n",
    "            VARIABLE=var\n",
    "        )\n",
    "\n",
    "with CourseSuite('internal_or_external_variable') as s:\n",
    "    with pf.Family('containing_family', MY_VAR=1234) as f:\n",
    "        TaskWithVariable('external_variable', f.MY_VAR)\n",
    "        TaskWithVariable('external_value', f.MY_VAR.value)\n",
    "        TaskWithVariable('default_value')\n",
    "        \n",
    "print(s)\n",
    "print(\"script external:\\n\", f.external_variable.script, '\\n')\n",
    "print(\"script default:\\n\", f.default_value.script, '\\n')\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General node properties\n",
    "\n",
    "Nodes and attributes have many accessible properties that can be accessed. Here is a non-exhaustive list of useful general node properties:\n",
    "\n",
    " - `suite` - The `Suite` object containing the node\n",
    " - `host()` - The currently active `Host` object\n",
    " - `anchor` - The current anchor (either `Suite` or `AnchorFamily`) containing this node\n",
    " - `name` - The visible name of this node\n",
    " - `fullname` - The full path of this node from the root\n",
    " - `all_children` - All (direct) children of a node\n",
    " - `all_executable_children` - All `Tasks` and `Families` (directly) contained within a `Family`\n",
    " - `all_tasks` - All `Tasks` (directly) contained within a `Family`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Constructs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyflow supports ecflow looping constructs, and ensures that they are initialised in a type-safe manner. The values of these looping constructs can be accessed from scripts in the same manner as normal ecflow variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/looping_constructs/set_labels.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/looping_constructs/set_labels.ecf\n",
      "Overwriting existing file: /Users/macw/git/pyflow/tutorials/course/scratch/files/looping_constructs/wait_2.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/looping_constructs/wait_2.ecf\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('looping_constructs') as s:\n",
    "    \n",
    "    with pf.Family('date_family'):\n",
    "        pf.RepeatDate('REPEAT_DATE',\n",
    "                      datetime.date(year=2019, month=1, day=1),\n",
    "                      datetime.date(year=2019, month=12, day=31))\n",
    "        \n",
    "        with pf.Family('hour_family', labels={'date_time': ''}) as f:\n",
    "            pf.RepeatInteger('REPEAT_HOUR', 1, 24)\n",
    "            (\n",
    "                LabelSetter((f.date_time, '$REPEAT_DATE hour $REPEAT_HOUR'))\n",
    "                >>\n",
    "                WaitSeconds(2)\n",
    "            )\n",
    "\n",
    "s.deploy_suite()\n",
    "s.replace_on_server(server_host, server_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions - Triggers, Completes\n",
    "\n",
    "Ecflow has a rich languge and (associated behaviour) for expressions that trigger dependencies and conditional behaviour in suites. These expressions are ultimately strings that are parsed by the ecflow server and evaluated to control the suite.\n",
    "\n",
    "Within pyflow, all of the components that make up ecflow expressions are already present as objects in the script. This means we can generate type-safe, validated expressions by using the existing objects directly. These can then be assigned to the `triggers` or `completes` attributes of any appropriate node.\n",
    "\n",
    "Trigger expressions should follow the natural arithmetic expressing the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    \n",
    "    with pf.Family('repeat1') as repeat1:\n",
    "        pf.RepeatDate('YMD', datetime.date(2019, 1, 1), datetime.date(2010, 12, 31))\n",
    "        \n",
    "    with pf.Family('repeat2') as repeat2:\n",
    "        pf.RepeatDate('YMD', datetime.date(2019, 1, 1), datetime.date(2010, 12, 31))\n",
    "        \n",
    "    repeat2.triggers = (repeat1 == pf.state.complete) | (repeat1.YMD > repeat2.YMD)\n",
    "        \n",
    "    pf.Task('t3').completes = (repeat2.YMD > '20190616')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcut - helper properties\n",
    "\n",
    "A number of shortcut properties exist to construct standard expression components. The following sets of examples are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MyTask('a_task')\n",
    "exprn = (t == pf.state.aborted)\n",
    "exprn = (t == pf.state.complete)\n",
    "exprn = (t == pf.state.unknown)\n",
    "exprn = (t == pf.state.queued)\n",
    "exprn = (t == pf.state.submitted)\n",
    "exprn = (t == pf.state.active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MyTask('a_task')\n",
    "exprn = t.aborted\n",
    "exprn = t.complete\n",
    "exprn = t.unknown\n",
    "exprn = t.queued\n",
    "exprn = t.submitted\n",
    "exprn = t.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Expressions\n",
    "\n",
    "Expressions can be combined with logical operators, both unary and binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    t1 = MyTask('t1')\n",
    "    t2 = MyTask('t2')\n",
    "    t3 = MyTask('t3')\n",
    "    \n",
    "    t1.triggers = t2.complete & t3.aborted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    t1 = MyTask('t1')\n",
    "    t2 = MyTask('t2')\n",
    "    t3 = MyTask('t3')\n",
    "    \n",
    "    t1.triggers = t2.complete\n",
    "    t1.triggers |= t3.aborted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcut - dependencies\n",
    "\n",
    "The most common trigger expression to express is one of dependencies. Task A runs only after Task B has completed. We provide a special operator to simplify this approach.\n",
    "\n",
    "The following are equivalent approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    t1 = MyTask('t1')\n",
    "    t2 = MyTask('t2')\n",
    "    t1.triggers = t2.complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    t1 = MyTask('t1')\n",
    "    t2 = MyTask('t2')\n",
    "    t1.triggers = (t2 == pf.state.complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    t1 = MyTask('t1')\n",
    "    t2 = MyTask('t2')\n",
    "    t1 >> t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite(\"s\"):\n",
    "    (\n",
    "        MyTask('t1')\n",
    "        >>\n",
    "        MyTask('t2')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to establish a dependency relationship between a large number of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Ecflow Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyflow builds its dependency trees using python objects. This means that if we wish to have connections to external suites, that are not built from the same repository, then we must build shadow objects that map to the nodes we wish to connect to.\n",
    "\n",
    "A full range of these `Extern*` objects exist which may be used in the normal way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pf.Suite('s'):\n",
    "    \n",
    "    etask = pf.ExternTask('/a/b/c/d')\n",
    "    efamily = pf.ExternFamily('/f/g/h/i')\n",
    "    \n",
    "    eymd = pf.ExternYMD('/a/b/c/d:YMD')\n",
    "    eevent = pf.ExternEvent('/e/f/g/h:ev')\n",
    "    emeter = pf.ExternMeter('/g/h/i/j:mt')\n",
    "    \n",
    "    t1 = pf.Task('t1')\n",
    "    t1.triggers = etask & efamily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-depth Functionality\n",
    "\n",
    "Pyflow aims to contain not just a collection of ecflow functionality, but also helper functionality to assist in building suites. Where idiomatic uses of ecflow result in the same mechanisms being built repeatedly, pyflow can incorporate these to help generate clearer suites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ecflow_name()` functionality converts an arbitrary string into a name which meets the character restrictions for ecflow nodes. This is very useful for converting strings such as hostnames or the names of various data sets into a form that can be used as the name of a Family or Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyphenated_name\n"
     ]
    }
   ],
   "source": [
    "print(pf.ecflow_name('hyphenated-name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `all_complete()` and `sequence()` functions facilitate working with generated sequences of python tasks. `all_complete()` generates an expression suitable for use in triggers (or completes). `sequence()` generates triggers such that all of the tasks will run sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite sequences\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/sequences'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  task t_0\n",
      "  task t_1\n",
      "    trigger t_0 eq complete\n",
      "  task t_2\n",
      "    trigger t_1 eq complete\n",
      "  task t_3\n",
      "    trigger t_2 eq complete\n",
      "  task t_4\n",
      "    trigger t_3 eq complete\n",
      "  task t_5\n",
      "    trigger t_4 eq complete\n",
      "  task t_6\n",
      "    trigger t_5 eq complete\n",
      "  task t_7\n",
      "    trigger t_6 eq complete\n",
      "  task t_8\n",
      "    trigger t_7 eq complete\n",
      "  task t_9\n",
      "    trigger t_8 eq complete\n",
      "  task done\n",
      "    trigger ((((((((t_0 eq complete and t_1 eq complete) and t_2 eq complete) and t_3 eq complete) and t_4 eq complete) and t_5 eq complete) and t_6 eq complete) and t_7 eq complete) and t_8 eq complete) and t_9 eq complete\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('sequences') as s:\n",
    "    tasks = [pf.Task('t_{}'.format(i)) for i in range(10)]\n",
    "    pf.Task('done', triggers=pf.all_complete(tasks))\n",
    "    pf.sequence(tasks)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common idiom in looping suites is to have two suites that both loop on dates/times, one which runs behind the other. For example the `lag` family running after the forecast has completed. This idiom can be expressed more clearly by encapsulating its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite follow\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"default\"\n",
      "  family leader\n",
      "    repeat date YMD 20190101 20191231 1\n",
      "  endfamily\n",
      "  family follower\n",
      "    trigger leader eq complete or follower:YMD lt leader:YMD\n",
      "    repeat date YMD 20190101 20191231 1\n",
      "  endfamily\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('follow') as s:\n",
    "    with pf.Family('leader') as leader:\n",
    "        pf.RepeatDate(\"YMD\", datetime.date(2019, 1, 1), datetime.date(2019, 12, 31))\n",
    "    with pf.Family('follower') as follower:\n",
    "        pf.RepeatDate(\"YMD\", datetime.date(2019, 1, 1), datetime.date(2019, 12, 31))\n",
    "    follower.follow = leader.YMD\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collection of utility functionality is (perpetually) in progress, and will be updated to account for useful idioms as they emerge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecflow is ultimately a framework for executing tasks, but task execution requires a context. Pyflow makes use of a `Host` object to supply the context for this execution. As such pyflow *requires* a host object to be defined before it will generate any executable nodes in the tree. The `host` can be set at any level (`Suite`, `Family` or `Task`) and is inherited unless overridden.\n",
    "\n",
    "If the default behaviour of ecflow is required, and task execution is being managed explicitly, the host may be set to `NullHost()` at the `Suite` level. This will suppress all host-related behaviour inside pyflow.\n",
    "\n",
    "For task handling, it is important that the `ecflow_client` is configured (via appropriate environment variables) and that it is correctly called to trigger changes of state in the server. Further, any and all errors that may occur in a script must be correctly caught and reported to the ecflow server.\n",
    "\n",
    "`Host` objects must also know how to transfer data to/from the host to be able to implement the Data Resource functionality discussed later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host Arguments\n",
    "\n",
    "Host classes have many configurable options, but some of these options are available for all host classes and configure the base Host class. Other than `name`, all of these are optional, keyword arguments with plausible defaults.\n",
    "\n",
    " * `name` - the name used for the host. Required (non keyword argument).\n",
    " * `hostname` - The hostname to run the task on. Defaults to `name` if not supplied\n",
    " * `scratch_directory` - The path in which tasks will be run, unless otherwise specified. Also to be used within suites when a scratch location is needed.\n",
    " * `log_directory` - The directory to use for script output. Defaults to `ECF_HOME`, but may need to be changed on systems with scheduling systems to make the output visible to the ecflow server.\n",
    " * `limit` - How many tasks can run on the node simultaneously.\n",
    " * `extra_paths` - Paths that are to be added to PATH on the host.\n",
    " * `extra_variables` - A dictionary of additional ECFLOW variables that should be set to configure the host (e.g. {'SCHOST': 'ccb'}).\n",
    " * `environment_variables` - Additional environment variables to export into all scripts.\n",
    " * `modules` - Modules to `module load`\n",
    " * `module_purge` - Should a `module purge` command be run (before loading any modules). Default False.\n",
    " * `module_source` - The shell script to source to initialise the module system. Default None.\n",
    " * `ecflow_path` - The directory containing the `ecflow_client` executable\n",
    " * `label_host` - When the `host` property is changed on a node, should a `Label` be created in the tree. Default True.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Host Classes\n",
    "\n",
    "A number of existing host clases have been defined. These can be extended, and alternatives provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LocalHost`\n",
    "\n",
    "This is essentially a trivial host. It runs tasks as background processes on the current node - i.e. on the ecflow server, and running as the same user as the server. Other than for examples, this is extremely useful for running tasks that update labels, meters, events and variables on a node that is certain to have the `ecflow_client` working correctly and with no job queuing delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.LocalHost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SSHHost`\n",
    "\n",
    "Run a script on a remote host which has been accessed by ssh. The `name` argument is treated as the target hostname unless the `hostname` keyword argument is explicitly supplied. By default the user that generated the pyflow suite is used, unless the `user` argument is supplied.\n",
    "\n",
    "The SSHHost is special in that it does not require the `ecflow_client` to be installed on the remote host and does not require the presence of any shared filesystems or log servers to make output logs visible to the user. All of the `ecflow_client` commands required are executed on the *server side*, and the script output is piped back through the SSH command.\n",
    "\n",
    "For these connections to be established, it is necessary that the ecflow server is configured to have SSH access to the target systems using SSH keys. Further, as this requires an SSH connection to be maintained for each of the running commands, it imposes a practical limit on the number of commands that can be run simultaneously on any remote host. There may be value in setting up SSH connections that persist across multiple commands, by making use of the `ControlMaster`, `ControlPath` and `ControlPersist` options in the ssh config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.SSHHost('dhs9999', user='max', scratch_directory='/data/a_mounted_filesystem/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSHHost class can also take additional optional arguments `indirect_host` and `indirect_user`. If `indirect_host` is supplied then a two-hop connection is made, such that a connection is made to the `indirect_host`, and then a further ssh connection is made to the real host. Note that this is not the same as using a `ProxyCommand` configured to a normal ssh connection - the credentials for the second hop are held on the intermediate system. `indirect_user` defaults to `user` if it is not supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.SSHHost('cloud-mvr001',\n",
    "                  user='mover-user',\n",
    "                  indirect_host='cloud-gateway',\n",
    "                  indirect_user='cloud-user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PBSHost`\n",
    "\n",
    "Connects to a remote host by ssh, and submits a job on the batch scheduling system. As this task will run asynchronously on a remote system this *requires* the `ecflow_client` to be available, and if it is not at the default location this should be configured with the `ecflow_path` keyword argument.\n",
    "\n",
    "It is anticipated that for real use this class will be derived from to add and configure site-specific functionality (such as knowledge of, and handling of, queues). See the example for hosts cca/ccb in `pyflow/hosts/cca.py`.\n",
    "\n",
    "It is likely that the `log_directory` will need to be modified, and the `ECF_LOGHOST` and `ECF_LOGPORT` variables are likely to be needed to operate with a log server to get output working fully.\n",
    "\n",
    "***This class is very much a work in progress, and is probably currently too ECMWF-specific***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SLURMHost`\n",
    "\n",
    "This executes scripts on a remote system, by ssh-ing in and submitting to the SLURM job scheduling system. This is very much analagous to the PBSHost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TroikaHost`\n",
    "\n",
    "This executes scripts on a remote system, by ssh-ing in and submitting the jobs using the Troika tool developed by ECWMF, which allows to abstract the job submission system using configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Discussion\n",
    "\n",
    "### For Discussion: Limits\n",
    "\n",
    "`Host` objects accept an argument `limit=`. This can be used to construct a limit (preferably in a sensible location within the suite). Once this has been set up then any `Task` that is created using this host object will automatically be added to the limit for the given host.\n",
    "\n",
    "Note that this implies that the same host *object* should be used to configure `Tasks` throughout the suite, rather than just using host objects that refer to the same host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite limits\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/limits'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family limits\n",
      "    limit localhost 3\n",
      "  endfamily\n",
      "  task t1\n",
      "    inlimit /limits/limits:localhost\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with CourseSuite('limits', host=pf.LocalHost('localhost', limit=3)) as s:\n",
    "    \n",
    "    with pf.Family('limits'):\n",
    "        s.host.build_limits()\n",
    "        \n",
    "    pf.Task('t1', script='I am limited')\n",
    "    \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Discussion: Is this useful functionality to have in pyflow, or should this be nuked?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Discussion: Job Characteristics\n",
    "\n",
    "In pyflow, a task is generated as a synthesis of multiple pieces of information:\n",
    "\n",
    " - The Task object in the suite - *when* to run\n",
    " - The Script object (script attribute on Task) - *what* to run\n",
    " - The Host object - *how* to run\n",
    " \n",
    "The combination of these three components provides the information to determine *when*, *what*, and *how* a task should be executed. The Host object is important as it provides two major components:\n",
    "\n",
    " 1. A mechanism by which a task should be executed. This reduces to the ECF_JOB_CMD and associated machinery.\n",
    " 2. Preamble and Postamble material that is used for consting the script to execute.\n",
    " \n",
    "Unfortunately, the breakdown is not nearly so clear in real life. Consider the case of one of the HPC machines. We can:\n",
    "\n",
    " - Run a task on the head node as a simple SSHHost\n",
    " - Submit a serial, fractional or parallel job\n",
    " - Submit jobs using various (machine specific) resource requirements\n",
    " \n",
    "This is a problem. Conceptually properties such as the number of cores and nodes, whether to use hyperthreading or hugepages are properties of the Task but they depend very strongly on the Host.\n",
    "\n",
    "Currently all properties that determine the execution process must belong to the Host. These can be parameterised to use Ecflow variables that are set on `Families` or `Tasks`, but this is a bit of a hack. We would like this parameterisation to only be needed if those properties should be changeable at runtime (e.g. by the operators).\n",
    "\n",
    "To Discuss: What should the API look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployable Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many hacks to deploy resources in suites, or resources can be managed and deployed out of band with the suite. It is, however, better to manage versioning of deployed resources in conjunction with the suite. This ensures that a deployed suite always runs what is expected.\n",
    "\n",
    "Pyflow provides a new mechanism for deploying resources as resources. This can include static data files and anything else that should already be in place for tasks to run correctly.\n",
    "\n",
    "***Do not use Resources to deploy scripts or other executable code.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Resource mechanism provides a decoupling between:\n",
    "    \n",
    " 1. Specifying what resource should be deployed (at suite generation time)\n",
    " 2. Obtaining the resource, and on which host this resource should be obtained\n",
    " 3. On which host(s) the resource should be deployed\n",
    " \n",
    "The host that runs the resource task can be selected by setting the host attribute on the Resources family. The hosts onto which the resources are deployed are specified in a list - this enables the suite to retrieve an external resource only once, even if it needs to be deployed to multiple locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pf\u001b[38;5;241m.\u001b[39mSuite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pf\u001b[38;5;241m.\u001b[39mResources(host\u001b[38;5;241m=\u001b[39mpf\u001b[38;5;241m.\u001b[39mLocalHost()):\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataResource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLocalHost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msome data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/pyflow/pyflow/resource.py:157\u001b[0m, in \u001b[0;36mDataResource.__init__\u001b[0;34m(self, name, hosts, source_data)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, hosts, source_data):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m source_data\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhosts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/pyflow/pyflow/resource.py:52\u001b[0m, in \u001b[0;36mResource.__init__\u001b[0;34m(self, name, hosts)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hosts \u001b[38;5;241m=\u001b[39m hosts \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hosts, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable) \u001b[38;5;28;01melse\u001b[39;00m [hosts]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_directory \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hosts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfullname\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hosts:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m h\u001b[38;5;241m.\u001b[39mresources_directory:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyflow_test/lib/python3.10/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(a, \u001b[38;5;241m*\u001b[39mp):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124;03m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(a)\n\u001b[1;32m     78\u001b[0m     path \u001b[38;5;241m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# BROKEN\n",
    "with pf.Suite('s'):\n",
    "    with pf.Resources(host=pf.LocalHost()):\n",
    "        pf.DataResource('script', [pf.LocalHost('localhost')], 'some data'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be retrieved from a number of types of location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pf\u001b[38;5;241m.\u001b[39mSuite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pf\u001b[38;5;241m.\u001b[39mResources():\n\u001b[1;32m      4\u001b[0m         \n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Deploy data directly from the python code\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataResource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLocalHost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthis is some data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Deploy data from a file accessible at generation time\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         pf\u001b[38;5;241m.\u001b[39mFileResource(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata2\u001b[39m\u001b[38;5;124m'\u001b[39m, [pf\u001b[38;5;241m.\u001b[39mLocalHost(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m)], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/data.dat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/git/pyflow/pyflow/resource.py:157\u001b[0m, in \u001b[0;36mDataResource.__init__\u001b[0;34m(self, name, hosts, source_data)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, hosts, source_data):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m source_data\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhosts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/pyflow/pyflow/resource.py:52\u001b[0m, in \u001b[0;36mResource.__init__\u001b[0;34m(self, name, hosts)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hosts \u001b[38;5;241m=\u001b[39m hosts \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hosts, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable) \u001b[38;5;28;01melse\u001b[39;00m [hosts]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_directory \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hosts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfullname\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hosts:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m h\u001b[38;5;241m.\u001b[39mresources_directory:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pyflow_test/lib/python3.10/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(a, \u001b[38;5;241m*\u001b[39mp):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124;03m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(a)\n\u001b[1;32m     78\u001b[0m     path \u001b[38;5;241m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# BROKEN\n",
    "with pf.Suite('s'):\n",
    "    with pf.Resources():\n",
    "        \n",
    "        # Deploy data directly from the python code\n",
    "        pf.DataResource('data1', [pf.LocalHost('localhost')], \"this is some data\".encode('utf-8'))\n",
    "        \n",
    "        # Deploy data from a file accessible at generation time\n",
    "        pf.FileResource('data2', [pf.LocalHost('localhost')], 'path/to/data.dat')\n",
    "        \n",
    "        # Deploy data accessible from a URL\n",
    "        pf.WebResource('data3', [pf.LocalHost('localhost')], 'htts://example.com/data')\n",
    "        pf.WebResource('data4', [pf.LocalHost('localhost')], 'htts://example.com/data', md5='0123456789abcdef')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resource class can be derived from to obtain more complex resources. The FDB test suite has a MARSResource that runs on a host that has a MARS client to obtain test data from MARS, and which is then transferred to the relevant hosts for testing the FDB tools (which do not have a working and configured MARS client able to interact with the operational MARS).\n",
    "\n",
    "To extend the functionality of a Resource class, the `get_resource` member function should be overriden to return an array of lines that can be combined into a script to be run on the Resource execution host to obtain the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script handling in pyflow\n",
    "\n",
    "Pyflow is designed to facilitate a number of modes of use:\n",
    "\n",
    " * Running scripts that already exist, or are developed outside of the pyflow suite.\n",
    " * Running scripts that are stand-alone in the pyflow suite.\n",
    " * Running scripts that are generated from pieces, and templated using pyflow objects.\n",
    " \n",
    "This enables clean pathways for migrating existing suites, whilst also giving flexibility for generated functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Locations\n",
    "\n",
    "ecflow uses a well defined strategy for locating the scripts to run. It looks in the location specified by ECF_FILES if it is specified, or ECF_HOME otherwise (these can be set using the `files=` or `home=` arguments to the Suite or to anchor families above).\n",
    "\n",
    "Then, given a specific script path /a/b/c/task the following locations will be considered (in order):\n",
    "\n",
    "```\n",
    "$ECF_FILES/a/b/c/task\n",
    "$ECF_FILES/b/c/task\n",
    "$ECF_FILES/c/task\n",
    "$ECF_FILES/task\n",
    "```\n",
    "\n",
    "This is designed for a use case such as the operational forecast suites, where tasks/families are grouped macroscopically at a high level (e.g. each forecast ensemble member), where all the tasks differ only by ECFLOW variables that have been set.\n",
    "\n",
    "In pyflow we define a type of Family called an AnchorFamily (a Suite counts as an AnchorFamily for this purpose). The value of ECF_FILES is updated for an AnchorFamily relative to the most recent parent AnchorFamily. All scripts within an AnchorFamily with the same name *must* be identical. Consider the suite layout:\n",
    "\n",
    "```\n",
    "Suite(s, files='root-path')\n",
    "  Task(t1)\n",
    "  Family(f1)\n",
    "    Task(t1)\n",
    "    Task(t2)\n",
    "    Task(t3)\n",
    "  Family(f2)\n",
    "    AnchorFamily(f3)\n",
    "      Task(t1)\n",
    "      Family(f1)\n",
    "        Task(t1)\n",
    "        Task(t2)\n",
    "        Task(t3)\n",
    "```\n",
    "\n",
    "This will correspond to an on disk arrangement of\n",
    "\n",
    "```\n",
    "root-path/\n",
    "  t1.ecf\n",
    "  t2.ecf\n",
    "  t3.ecf\n",
    "  f2/\n",
    "    f3/\n",
    "      t1.ecf\n",
    "      t2.ecf\n",
    "      t3.ecf\n",
    "```\n",
    "\n",
    "If the scripts are generated within pyflow then the appropriate uniqueness of scripts will be tested at generation time, and they will be automatically deployed to these locations. If scripts are supplied by the user outside of pyflow, they should be supplied to match this structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Generation\n",
    "Scripts are generated by a combination of:\n",
    "\n",
    " 1. The script attribute of the task (a Script object)\n",
    " 2. Attributes of the Task object\n",
    " 3. The execution host (which may be an attribute of the Task object, or one of its parents)\n",
    " \n",
    "The simplest example of a script can be seen here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>File: /s/t.ecf</h3><hr><pre><span style=\"font-style: italic;color: blue\">#!/bin/bash</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Running on: $(hostname)\" || true\n",
       "<span style=\"text-weight: bold; color: green\">set</span> -uex\n",
       "\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PORT=<span style=\"color: red\">%ECF_PORT%</span>    <span style=\"font-style: italic;color: blue\"># The server port number</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_HOST=<span style=\"color: red\">%ECF_HOST%</span>    <span style=\"font-style: italic;color: blue\"># The host name where the server is running</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_NAME=<span style=\"color: red\">%ECF_NAME%</span>    <span style=\"font-style: italic;color: blue\"># The name of this current task</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PASS=<span style=\"color: red\">%ECF_PASS%</span>    <span style=\"font-style: italic;color: blue\"># A unique password</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_TRYNO=<span style=\"color: red\">%ECF_TRYNO%</span>  <span style=\"font-style: italic;color: blue\"># Current try number of the task</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Current working directory: $(pwd)\"\n",
       "\n",
       "%nopp\n",
       "\n",
       "Running on $ECF_HOST\n",
       "\n",
       "%end\n",
       "</pre><hr>"
      ],
      "text/plain": [
       "<pyflow.deployment.Notebook at 0x115a36e30>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " with pf.Suite('s', host=pf.LocalHost('localhost'), files='/s') as s:\n",
    "    pf.Task('t', script='Running on $ECF_HOST')\n",
    "    \n",
    "s.deploy_suite(target=pf.deployment.Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the script is automatically run with `set -uex`. As such any access to undefined variables, or any commands that fail, will trigger failure of the overall script. If the success of individual commands needs to be tested, this behaivour will need to be selectively turned off (`set +e`).\n",
    "\n",
    "The script proper is placed within a `%nopp / %end` pair. As such, explicit access to ecflow pre-processing is not available in the script object.\n",
    "\n",
    "If the host has more complicated behaviour, the preamble and postamble applied are more complex. In particular, if the ecflow_client is (known to be) available on the target host then the relevant environment/ecflow variables are introduced, and the `PATH` is updated such that the ecflow_client is available.\n",
    "\n",
    "This is also coupled with:\n",
    "\n",
    " 1. Access to referenced ecflow Variables (or other exportable objects, such as Repeats).\n",
    " 2. Manuals\n",
    " 3. Modules\n",
    " 4. Working directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>File: /s/t.ecf</h3><hr><pre>%manual\n",
       "This is a multi-line manual\n",
       "which can contain instructions\n",
       "%end\n",
       "<span style=\"font-style: italic;color: blue\">#!/bin/bash</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Running on: $(hostname)\" || true\n",
       "<span style=\"text-weight: bold; color: green\">set</span> -uex\n",
       "\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PORT=<span style=\"color: red\">%ECF_PORT%</span>    <span style=\"font-style: italic;color: blue\"># The server port number</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_HOST=<span style=\"color: red\">%ECF_HOST%</span>    <span style=\"font-style: italic;color: blue\"># The host name where the server is running</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_NAME=<span style=\"color: red\">%ECF_NAME%</span>    <span style=\"font-style: italic;color: blue\"># The name of this current task</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PASS=<span style=\"color: red\">%ECF_PASS%</span>    <span style=\"font-style: italic;color: blue\"># A unique password</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_TRYNO=<span style=\"color: red\">%ECF_TRYNO%</span>  <span style=\"font-style: italic;color: blue\"># Current try number of the task</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> A_VARIABLE=\"<span style=\"color: red\">%A_VARIABLE%</span>\"\n",
       "\n",
       "module <span style=\"text-weight: bold; color: green\">rm</span> ecbuild &amp;&gt; /dev/null || true\n",
       "module load ecbuild &amp;&gt; /dev/null\n",
       "\n",
       "[[ -d \"/tmp/pyflow/s\" ]] || <span style=\"text-weight: bold; color: green\">mkdir</span> -p \"/tmp/pyflow/s\"\n",
       "<span style=\"text-weight: bold; color: green\">cd</span> \"/tmp/pyflow/s\"\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Current working directory: $(pwd)\"\n",
       "\n",
       "%nopp\n",
       "\n",
       "Running on $ECF_HOST\n",
       "Variable value $A_VARIABLE\n",
       "\n",
       "%end\n",
       "</pre><hr>"
      ],
      "text/plain": [
       "<pyflow.deployment.Notebook at 0x1159f92a0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pf.Suite('s', host=pf.LocalHost(), files='/s', A_VARIABLE='has a value') as s:\n",
    "    pf.Task('t',\n",
    "            script='Running on $ECF_HOST\\nVariable value $A_VARIABLE',\n",
    "            manual=\"This is a multi-line manual\\nwhich can contain instructions\",\n",
    "            workdir='/tmp/pyflow/s',\n",
    "            modules=['ecbuild'])\n",
    "    \n",
    "s.deploy_suite(target=pf.deployment.Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a valid script\n",
    "\n",
    "Pyflow scripts are instances of the Script class. At generation time, these call some composition functionality to combine script fragments (in the `generate_stub` method) and then call the `generate` method which can be overridden to provide customisable functionality. A number of Script types can be found in the source file `pyflow/script.py`.\n",
    "\n",
    "Scripts are automatically generated from simple strings or lists of other objects that are convertible to Scripts themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyflow.script.Script'>\n",
      "echo \"I am a simple script\"\n"
     ]
    }
   ],
   "source": [
    "t = pf.Task('t', script='echo \"I am a simple script\"')\n",
    "print(type(t.script))\n",
    "print(t.script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyflow.script.Script'>\n",
      "echo \"I am the first line\"\n",
      "echo \"I am the second line\"\n",
      "echo \"and I am the third\"\n"
     ]
    }
   ],
   "source": [
    "t = pf.Task('t', script=[\n",
    "    'echo \"I am the first line\"',\n",
    "    'echo \"I am the second line\"\\necho \"and I am the third\"'\n",
    "])\n",
    "print(type(t.script))\n",
    "print(t.script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts can be loaded from files. Additional environment variables can be supplied explicitly (they can also be supplied by the host).\n",
    " \n",
    "In pyflow we aim to minimise the number of environment variables that are made available to scripts and the number of Variables (and other ecflow objects) that are exported to the scripts. This is typically done by analysing the scripts for references to the variables used which are then automatically exported.\n",
    "\n",
    "There are cases, especially where environment variables are used by opaque binaries, where this exporting cannot be automatic. In these contexts, environment variables can be explicitly exported using the `Script.define_environment_variable(name, value)` function, and pyflow objects can be explicitly exported by using the `Script.force_exported` function. These should be used *minimally* to make scripts work such that we keep generated scripts to minimal length and complexity, and that it is clear what interdependencies actually exist.\n",
    "\n",
    "i.e. there should not be large numbers of environment variables or ecflow variable exports contained in included header files shared between many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>File: None</h3><hr><pre><span style=\"font-style: italic;color: blue\">#!/bin/bash</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Running on: $(hostname)\" || true\n",
       "<span style=\"text-weight: bold; color: green\">set</span> -uex\n",
       "\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PORT=<span style=\"color: red\">%ECF_PORT%</span>    <span style=\"font-style: italic;color: blue\"># The server port number</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_HOST=<span style=\"color: red\">%ECF_HOST%</span>    <span style=\"font-style: italic;color: blue\"># The host name where the server is running</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_NAME=<span style=\"color: red\">%ECF_NAME%</span>    <span style=\"font-style: italic;color: blue\"># The name of this current task</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_PASS=<span style=\"color: red\">%ECF_PASS%</span>    <span style=\"font-style: italic;color: blue\"># A unique password</span>\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ECF_TRYNO=<span style=\"color: red\">%ECF_TRYNO%</span>  <span style=\"font-style: italic;color: blue\"># Current try number of the task</span>\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> DEBUG=\"<span style=\"color: red\">%DEBUG%</span>\"\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Current working directory: $(pwd)\"\n",
       "\n",
       "%nopp\n",
       "\n",
       "<span style=\"text-weight: bold; color: green\">export</span> ENV1=\"1234\"\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"I am a sample script\"\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"With multiple lines\"\n",
       "<span style=\"text-weight: bold; color: green\">echo</span> \"Env variable ENV1: $ENV1\"\n",
       "\n",
       "\n",
       "%end\n",
       "</pre><hr>"
      ],
      "text/plain": [
       "<pyflow.deployment.Notebook at 0x1159ed7e0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config:\n",
    "    debug = 1\n",
    "config = Config()\n",
    "\n",
    "with pf.Suite('exporting', host=pf.LocalHost()) as s:\n",
    "    with pf.Task('mars', DEBUG=config.debug) as t:\n",
    "        t.script = pf.FileScript('sample_script.sh')\n",
    "        t.script.define_environment_variable(\"ENV1\", 1234)\n",
    "        t.script.force_exported(t.DEBUG)\n",
    "\n",
    "s.deploy_suite(target=pf.deployment.Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script templating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to be able to build scripts out of paramaterisable components. These have two major advantages:\n",
    "\n",
    " 1. Script components can be reused in multiple contexts, which encourages modular and object-oriented suite design.\n",
    " 2. Referenced pyflow objects (Variables, Tasks, Labels, ...) are expanded at suite/script generation time, and any referencing errors will be caught at that point. This makes it easy to change the names of ecflow nodes and avoid runtime errors from missing symbols (including by typos).\n",
    " \n",
    "Templating uses the Jinja2 engine. This is a very powerful templating engine for building templated scripts in a python environment. From pyflow, objects should be supplied to the templates as arguments to the TemplateScript object or TemplateFileScript object.\n",
    " \n",
    "An example follows where Labels attached to a task are updated according to the ecflow variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecflow_client --alter=change label date_label \"$DATE_REPEAT\" /s/a_task\n",
      "ecflow_client --alter=change label var_label \"$A_VARIABLE\" /s/a_task\n",
      "ecflow_client --alter=change label static_label \"some static text\" /s/a_task\n"
     ]
    }
   ],
   "source": [
    "def update_label(label, text):\n",
    "    return pf.TemplateScript(\n",
    "        'ecflow_client --alter=change label {{ LABEL.name }} \"{{ TEXT }}\" {{ LABEL.parent.fullname }}',\n",
    "        LABEL=label,\n",
    "        TEXT=text\n",
    "    )\n",
    "\n",
    "\n",
    "with pf.Suite('s', A_VARIABLE=1234) as s:\n",
    "    pf.RepeatDate('DATE_REPEAT',\n",
    "                  datetime.date(year=2019, month=1, day=1),\n",
    "                  datetime.date(year=2019, month=12, day=31))\n",
    "    \n",
    "    t = pf.Task('a_task', labels={'date_label': '', 'var_label': '', 'static_label': ''})\n",
    "    t.script = [\n",
    "        update_label(t.date_label, s.DATE_REPEAT),\n",
    "        update_label(t.var_label, s.A_VARIABLE),\n",
    "        update_label(t.static_label, 'some static text')\n",
    "    ]\n",
    "     \n",
    "print(t.script)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templatable scripts can be loaded from files, and any valid Script object can be used as the input into a TemplateScript object. Once a script object exists, additional parameters can be added using the `add_parameters` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo \"A am a templated sample script\"\n",
      "echo \"I belong to task a_task with full path /s/a_task\"\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "echo \"I am a sample script\"\n",
      "echo \"With multiple lines\"\n",
      "echo \"Env variable ENV1: $ENV1\"\n",
      "\n",
      "Current task: another_task (/s/another_task, in suite s)\n",
      "Variable A_VARIABLE has value $A_VARIABLE, and started with value 1234\n",
      "And date: $DATE_REPEAT\n"
     ]
    }
   ],
   "source": [
    "with pf.Suite('s', A_VARIABLE=1234) as s:\n",
    "    pf.RepeatDate('DATE_REPEAT',\n",
    "                  datetime.date(year=2019, month=1, day=1),\n",
    "                  datetime.date(year=2019, month=12, day=31))\n",
    "    \n",
    "    t = pf.Task('a_task')\n",
    "    t.script = pf.TemplateFileScript('template_sample_script.sh', TASK=t)\n",
    "    \n",
    "    t2 = pf.Task('another_task')\n",
    "    t2.script = pf.TemplateScript([\n",
    "            pf.FileScript('sample_script.sh'),\n",
    "            'Current task: {{ TASK.name }} ({{ TASK.fullname }}, in suite {{ TASK.suite.name }})',\n",
    "            'Variable {{ VAR.name }} has value {{ VAR }}, and started with value {{ VAR.value }}',\n",
    "            'And date: {{ DATE }}'\n",
    "        ],\n",
    "        TASK=t2\n",
    "    )\n",
    "    t2.script.add_parameters(VAR=s.A_VARIABLE, DATE=s.DATE_REPEAT)\n",
    "    \n",
    "print(t.script)\n",
    "print(\"\\n------------------------------------\\n\")\n",
    "print(t2.script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Examples (more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Suite Structure\n",
    "\n",
    "One of the goals of building an Object-Oriented suite is avoiding tangled, procedural complexity in constructing suites. Making a suite configurable, and multi-purpose requires conditionality in how the suite is constructed.\n",
    "\n",
    "The most obvious way to do this is to put conditional expressions, namely if statements, into the suite structure. This works, but leads to a long-term increase in the complexity of the suite. But worse, it puts the configuration- and system-dependent logic about how a suite should be built into the structure of the suite rather than with the configuration where it belongs.\n",
    "\n",
    "This example shows delegation of conditional behaviour to a configuration, such that the configuration can use arbitrary logic and complexity (in this case just a lookup) to determine which subsections of a suite get built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    def __init__(self, **tests):\n",
    "        \n",
    "        # Default tests that should be built. Otherwise assume not\n",
    "        self.enabled_tests = {\n",
    "            'test3': True\n",
    "        }\n",
    "        self.enabled_tests.update(tests)\n",
    "        \n",
    "    def build_test(self, cls, name, *args, **kwargs):\n",
    "        if self.enabled_tests.get(name, False):\n",
    "            return cls(name, *args, **kwargs)\n",
    "        \n",
    "        \n",
    "class ATest(pf.Task):\n",
    "    def __init__(self, name, val):\n",
    "        super().__init__(name, script=\"echo test={} : val={}\".format(name, val))\n",
    "        \n",
    "\n",
    "class TestingSuite(CourseSuite):\n",
    "    \n",
    "    def __init__(self, name, config, **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        with self:\n",
    "            config.build_test(ATest, 'test1', 1234)\n",
    "            config.build_test(ATest, 'test2', 4321)\n",
    "            config.build_test(ATest, 'test3', 6666)\n",
    "            config.build_test(ATest, 'test4', 7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite default_tests\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/default_tests'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  task test3\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TestingSuite('default_tests', Config()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite add_test4\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/add_test4'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  task test3\n",
      "  task test4\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TestingSuite('add_test4', Config(test4=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite override_default_test\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/override_default_test'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  task test1\n",
      "  task test2\n",
      "endsuite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TestingSuite('override_default_test', Config(test1=True, test2=True, test3=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Delegation\n",
    "\n",
    "This first example demonstrates delegating a structural decision to a configuration object. We wish to loop over two different axes - one an integer axis, and the other a string based one. The configuration objects decide how this should be done, and the order of the looping.\n",
    "\n",
    "Further configuration objects can be derived from `Config1` and `Config2` to update the values, while leaving the structures the same.\n",
    "\n",
    "Once the suite has delegated construction of the looping structure to the config, the construction of the tasks within the looping structure can be continued in the normal way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suite config_string_integer\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/config_string_integer'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family string_looper\n",
      "    repeat enumerated REPEAT_STRING \"a\" \"b\" \"c\" \"d\" \"e\"\n",
      "    family integer_looper\n",
      "      repeat integer REPEAT_INTEGER 1 5\n",
      "      label info \"\"\n",
      "      task set_labels\n",
      "      task wait_2\n",
      "        trigger set_labels eq complete\n",
      "    endfamily\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "suite config_integer_string\n",
      "  defstatus suspended\n",
      "  edit ECF_FILES '/Users/macw/git/pyflow/tutorials/course/scratch/files/config_integer_string'\n",
      "  edit ECF_HOME '/Users/macw/git/pyflow/tutorials/course/scratch/out'\n",
      "  edit ECF_JOB_CMD 'bash -c 'export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/Users/macw/opt/miniconda3/envs/pyflow_test/bin:$PATH; ecflow_client --init=\"$$\" && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort ' 1> %ECF_JOBOUT% 2>&1 &'\n",
      "  edit ECF_KILL_CMD 'pkill -15 -P %ECF_RID%'\n",
      "  edit ECF_STATUS_CMD 'true'\n",
      "  edit ECF_OUT '%ECF_HOME%'\n",
      "  label exec_host \"localhost\"\n",
      "  family integer_looper\n",
      "    repeat integer REPEAT_INTEGER 1 5\n",
      "    family string_looper\n",
      "      repeat enumerated REPEAT_STRING \"a\" \"b\" \"c\" \"d\" \"e\"\n",
      "      label info \"\"\n",
      "      task set_labels\n",
      "      task wait_2\n",
      "        trigger set_labels eq complete\n",
      "    endfamily\n",
      "  endfamily\n",
      "endsuite\n",
      "\n",
      "Create directory: /Users/macw/git/pyflow/tutorials/course/scratch/files/config_string_integer\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/config_string_integer/set_labels.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/config_string_integer/wait_2.ecf\n",
      "Create directory: /Users/macw/git/pyflow/tutorials/course/scratch/files/config_integer_string\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/config_integer_string/set_labels.ecf\n",
      "Save /Users/macw/git/pyflow/tutorials/course/scratch/files/config_integer_string/wait_2.ecf\n"
     ]
    }
   ],
   "source": [
    "class ConfigBase:\n",
    "    suite_name = None\n",
    "    min_integer = 1\n",
    "    max_integer = 5\n",
    "    strings = ['a', 'b', 'c', 'd', 'e']\n",
    "    \n",
    "    def build_nested_loops(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Config1(ConfigBase):\n",
    "    suite_name = 'config_string_integer'\n",
    "    def build_nested_loops(self, **kwargs):\n",
    "        with pf.Family('string_looper'):\n",
    "            pf.RepeatEnumerated('REPEAT_STRING', self.strings)\n",
    "            with pf.Family('integer_looper', **kwargs) as inner:\n",
    "                pf.RepeatInteger('REPEAT_INTEGER', self.min_integer, self.max_integer)\n",
    "        return inner\n",
    "    \n",
    "class Config2(ConfigBase):\n",
    "    suite_name = 'config_integer_string'\n",
    "    def build_nested_loops(self, **kwargs):\n",
    "        with pf.Family('integer_looper'):\n",
    "            pf.RepeatInteger('REPEAT_INTEGER', self.min_integer, self.max_integer)\n",
    "            with pf.Family('string_looper', **kwargs) as inner:\n",
    "                pf.RepeatEnumerated('REPEAT_STRING', self.strings)\n",
    "        return inner\n",
    "              \n",
    "class NestedLoopingSuite(CourseSuite):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config.suite_name)\n",
    "        \n",
    "        with self:\n",
    "            with config.build_nested_loops(labels={'info': ''}) as f:\n",
    "                (                \n",
    "                    LabelSetter((f.info, '$REPEAT_INTEGER : $REPEAT_STRING'))\n",
    "                    >>\n",
    "                    WaitSeconds(2)\n",
    "                )\n",
    "    \n",
    "s1 = NestedLoopingSuite(Config1())\n",
    "print(s1)\n",
    "print('\\n------------------------------------------------\\n')\n",
    "s2 = NestedLoopingSuite(Config2())\n",
    "print(s2)\n",
    "\n",
    "s1.deploy_suite()\n",
    "s1.replace_on_server(server_host, server_port)\n",
    "s2.deploy_suite()\n",
    "s2.replace_on_server(server_host, server_port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
