{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec19c0a-66c9-4211-99d0-67b955e38be6",
   "metadata": {},
   "source": [
    "# Host Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716525b7-1770-4947-943a-553176228217",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Following code is needed to preconfigure this notebook\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../../..'))\n",
    "\n",
    "import pyflow as pf\n",
    "\n",
    "scratchdir = os.path.join('/', 'path', 'to', 'scratch')\n",
    "filesdir = os.path.join(scratchdir, 'files')\n",
    "outdir = os.path.join(scratchdir, 'out')\n",
    "\n",
    "\n",
    "class CourseSuite(pf.Suite):\n",
    "    \"\"\"\n",
    "    This CourseSuite object will be used throughout the course to provide sensible\n",
    "    defaults without verbosity\n",
    "    \"\"\"\n",
    "    def __init__(self, name, **kwargs):\n",
    "        \n",
    "        config = {\n",
    "            'host': pf.LocalHost(),\n",
    "            'files': os.path.join(filesdir, name),\n",
    "            'home': outdir,\n",
    "            'defstatus': pf.state.suspended\n",
    "        }\n",
    "        config.update(kwargs)\n",
    "        \n",
    "        super().__init__(name, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59011038-40d6-4e40-9664-c8052c789b0a",
   "metadata": {},
   "source": [
    "**ecFlow** is ultimately a framework for executing tasks, but task execution requires a context. **pyflow** makes use of a `Host` object to supply the context for this execution. As such **pyflow** _requires_ a host object to be defined before it will generate any executable nodes in the tree. The `host` can be set at any level (`Suite`, `Family` or `Task`) and is inherited unless overridden.\n",
    "\n",
    "If the default behaviour of **ecFlow** is required, and task execution is being managed explicitly, the host may be set to `NullHost()` at the `Suite` level. This will suppress all host-related behaviour inside **pyflow**.\n",
    "\n",
    "For task handling, it is important that the `ecflow_client` is configured (via appropriate environment variables) and that it is correctly called to trigger changes of state in the server. Further, any and all errors that may occur in a script must be correctly caught and reported to the **ecFlow** server."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2a63a24-0dc3-4673-9f33-8872849ef67c",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "``Host`` objects must also know how to transfer data to/from the host to be able to implement the :doc:`/content/introductory-course/deployable-resources` functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063d8c4-7c37-46bd-a2fc-c32fdd9ec37f",
   "metadata": {},
   "source": [
    "## Host Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18daffdc-a8e4-409a-badb-b2762df6410b",
   "metadata": {},
   "source": [
    "Host classes have many configurable options, but some of these options are available for all host classes and configure the base `Host` class. Other than `name`, all of these are optional, keyword arguments with plausible defaults.\n",
    "\n",
    "* `name` - the name used for the host. Required (non keyword argument).\n",
    "* `hostname` - The hostname to run the task on. Defaults to `name` if not supplied\n",
    "* `scratch_directory` - The path in which tasks will be run, unless otherwise specified. Also to be used within suites when a scratch location is needed.\n",
    "* `log_directory` - The directory to use for script output. Defaults to `ECF_HOME`, but may need to be changed on systems with scheduling systems to make the output visible to the **ecFlow** server.\n",
    "* `resources_directory` - The directory to use for suite resources. By default, `scratch_directory` is used.\n",
    "* `limit` - How many tasks can run on the node simultaneously.\n",
    "* `extra_paths` - Paths that are to be added to `PATH` on the host.\n",
    "* `extra_variables` - A dictionary of additional `ECFLOW` variables that should be set to configure the host (e.g. `{'SCHOST': 'hpc'}`).\n",
    "* `environment_variables` - Additional environment variables to export into all scripts.\n",
    "* `module_source` - The shell script to source to initialise the module system. Default `None`.\n",
    "* `modules` - Modules to `module load`\n",
    "* `purge_modules` - Should a `module purge` command be run (before loading any modules). Default `False`.\n",
    "* `label_host` - Whether to create an `exec_host` label on nodes where this host is freshly set. Default `True`.\n",
    "* `user` - The user running the script. May be used to determine paths, or for login details. Defaults to current user.\n",
    "* `ecflow_path` - The directory containing the `ecflow_client` executable\n",
    "* `server_ecfvars` - If true, don't define `ECF_JOB_CMD`, `ECF_KILL_CMD`, `ECF_STATUS_CMD` and `ECF_OUT` variables and use defaults from server.\n",
    "* `submit_arguments` - A dictionary of arguments to pass to the scheduler when submitting jobs, which each key is a label that can be referenced when creating tasks with the `Host` instance.\n",
    "* `workdir` - Work directory for every task executed within the `Host` instance, if not overriden for a Node.\n",
    "* `trap_signals` - The list of signals to trap. A default list is used if not set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fd3df-ed22-4821-a6aa-12deaac2c8d9",
   "metadata": {},
   "source": [
    "## Existing Host Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef67f44-4bd2-490f-9efa-a23fb572add3",
   "metadata": {},
   "source": [
    "A number of existing host clases have been defined. These can be extended, and alternatives provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a9308-9e87-46fc-8788-0c66d1259f64",
   "metadata": {},
   "source": [
    "### `LocalHost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d2297-f013-437f-adf9-2cc3f4aa9ab1",
   "metadata": {},
   "source": [
    "This is essentially a trivial host. It runs tasks as background processes on the current node - i.e. on the ecflow server, and running as the same user as the server. Other than for examples, this is extremely useful for running tasks that update labels, meters, events and variables on a node that is certain to have the `ecflow_client` working correctly and with no job queuing delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00c92f5-2857-498c-a931-8e633510b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.LocalHost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34b9b9-a096-4c08-b841-b626dc2fd9c2",
   "metadata": {},
   "source": [
    "### `SSHHost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78783a39-1c8f-49f7-b6df-b3a931a3ed10",
   "metadata": {},
   "source": [
    "Run a script on a remote host which has been accessed by SSH. The `name` argument is treated as the target hostname unless the `hostname` keyword argument is explicitly supplied. By default the user that generated the **pyflow** suite is used, unless the `user` argument is supplied.\n",
    "\n",
    "The `SSHHost` is special in that it does not require the `ecflow_client` to be installed on the remote host and does not require the presence of any shared filesystems or log servers to make output logs visible to the user. All of the `ecflow_client` commands required are executed on the _server side_, and the script output is piped back through the SSH command.\n",
    "\n",
    "For these connections to be established, it is necessary that the ecflow server is configured to have SSH access to the target systems using SSH keys. Further, as this requires an SSH connection to be maintained for each of the running commands, it imposes a practical limit on the number of commands that can be run simultaneously on any remote host. There may be value in setting up SSH connections that persist across multiple commands, by making use of the `ControlMaster`, `ControlPath` and `ControlPersist` options in the ssh config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e2a324-3df0-4874-8c69-d3d93ea39bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.SSHHost('dhs9999', user='max', scratch_directory='/data/a_mounted_filesystem/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda70dad-9981-4f50-b649-cbf90416f86d",
   "metadata": {},
   "source": [
    "The `SSHHost` class can also take additional optional arguments `indirect_host` and `indirect_user`. If `indirect_host` is supplied then a two-hop connection is made, such that a connection is made to the `indirect_host`, and then a further SSH connection is made to the real host. Note that this is not the same as using a `ProxyCommand` configured to a normal SSH connection - the credentials for the second hop are held on the intermediate system. `indirect_user` defaults to `user` if it is not supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5ffc60-7ffc-436e-840f-f84856c5719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = pf.SSHHost('cloud-mvr001',\n",
    "                  user='mover-user',\n",
    "                  indirect_host='cloud-gateway',\n",
    "                  indirect_user='cloud-user')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36ddbc-d24c-4a8e-9c5c-e94c98e462b8",
   "metadata": {},
   "source": [
    "### `PBSHost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1992697-768a-4e56-9f5d-612c71bcba69",
   "metadata": {},
   "source": [
    "Connects to a remote host by SSH, and submits a job on the batch scheduling system. As this task will run asynchronously on a remote system this _requires_ the `ecflow_client` to be available, and if it is not at the default location this should be configured with the `ecflow_path` keyword argument.\n",
    "\n",
    "It is anticipated that for real use this class will be derived from to add and configure site-specific functionality (such as knowledge of, and handling of, queues).\n",
    "\n",
    "It is likely that the `log_directory` will need to be modified, and the `ECF_LOGHOST` and `ECF_LOGPORT` variables are likely to be needed to operate with a log server to get output working fully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b336f-cac0-4f3d-b885-242485c67638",
   "metadata": {},
   "source": [
    "### `SLURMHost`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409126a-a918-4cc3-8e6e-344757837b3a",
   "metadata": {},
   "source": [
    "This executes scripts on a remote system, by ssh-ing in and submitting to the SLURM job scheduling system. This is very much analagous to the `PBSHost`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d9324ff-061a-4a17-be38-5870bf0e1c15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    ".. _`limits`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b72a8b-ce4b-4fac-90f4-1ddd778f2e34",
   "metadata": {},
   "source": [
    "## Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a538f05-e925-46ed-8ed6-bb976a277a21",
   "metadata": {},
   "source": [
    "`Host` objects accept an argument `limit=`. This can be used to construct a limit (preferably in a sensible location within the suite). Once this has been set up then any `Task` that is created using this host object will automatically be added to the limit for the given host.\n",
    "\n",
    "Note that this implies that the same host _object_ should be used to configure `Tasks` throughout the suite, rather than just using host objects that refer to the same host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f8f280-33bb-489a-9cfc-b33190d7211c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><span style=\"text-weight: bold; color: green\">suite</span> limits\n",
       "  <span style=\"text-weight: bold; color: green\">defstatus</span> suspended\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_FILES <span style=\"color: red\">'/path/to/scratch/files/limits'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_HOME <span style=\"color: red\">'/path/to/scratch/out'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_JOB_CMD <span style=\"color: red\">'bash -c '</span>export ECF_PORT=%ECF_PORT%; export ECF_HOST=%ECF_HOST%; export ECF_NAME=%ECF_NAME%; export ECF_PASS=%ECF_PASS%; export ECF_TRYNO=%ECF_TRYNO%; export PATH=/usr/local/apps/ecflow/%ECF_VERSION%/bin:$PATH; ecflow_client --init=<span style=\"color: red\">\"$$\"</span> && %ECF_JOB% && ecflow_client --complete || ecflow_client --abort <span style=\"color: red\">' 1> %ECF_JOBOUT% 2>&1 &'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_KILL_CMD <span style=\"color: red\">'pkill -15 -P %ECF_RID%'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_STATUS_CMD <span style=\"color: red\">'true'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">edit</span> ECF_OUT <span style=\"color: red\">'%ECF_HOME%'</span>\n",
       "  <span style=\"text-weight: bold; color: green\">label</span> exec_host <span style=\"color: red\">\"localhost\"</span>\n",
       "  <span style=\"text-weight: bold; color: green\">family</span> limits\n",
       "    <span style=\"text-weight: bold; color: green\">limit</span> localhost 3\n",
       "  <span style=\"text-weight: bold; color: green\">endfamily</span>\n",
       "  <span style=\"text-weight: bold; color: green\">task</span> t1\n",
       "    <span style=\"text-weight: bold; color: green\">inlimit</span> /limits/limits:localhost\n",
       "<span style=\"text-weight: bold; color: green\">endsuite</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "CourseSuite(/limits)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with CourseSuite('limits', host=pf.LocalHost(limit=3)) as s:\n",
    "    \n",
    "    with pf.Family('limits'):\n",
    "        s.host().build_limits()\n",
    "        \n",
    "    pf.Task('t1', script='I am limited')\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1df8f3-c6ec-4186-8952-04337716c55f",
   "metadata": {},
   "source": [
    "## Job Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b496e-3151-41c4-8798-fea38ba530d4",
   "metadata": {},
   "source": [
    "In **pyflow**, a task is generated as a synthesis of multiple pieces of information:\n",
    "\n",
    "- The Task object in the suite - _when_ to run\n",
    "- The Script object (script attribute on Task) - _what_ to run\n",
    "- The Host object - *how* to run\n",
    " \n",
    "The combination of these three components provides the information to determine _when_, _what_, and _how_ a task should be executed. The Host object is important as it provides two major components:\n",
    "\n",
    "1. A mechanism by which a task should be executed. This reduces to the `ECF_JOB_CMD` and associated machinery.\n",
    "2. Preamble and Postamble material that is used for consting the script to execute.\n",
    " \n",
    "Unfortunately, the breakdown is not nearly so clear in real life. Consider the case of one of the HPC machines. We can:\n",
    "\n",
    "- Run a task on the head node as a simple SSHHost\n",
    "- Submit a serial, fractional or parallel job\n",
    "- Submit jobs using various (machine specific) resource requirements\n",
    " \n",
    "This is a problem. Conceptually properties such as the number of cores and nodes, whether to use hyperthreading or hugepages are properties of the Task but they depend very strongly on the Host.\n",
    "\n",
    "Currently all properties that determine the execution process must belong to the Host. These can be parameterised to use **ecFlow** variables that are set on `Families` or `Tasks`, but this is a bit of a hack. We would like this parameterisation to only be needed if those properties should be changeable at runtime (e.g. by the operators).\n",
    "\n",
    "The `Host` `submit_arguments` dictionary is used to pass arguments to the scheduler when submitting jobs. Each key in this dictionary is a label that can be referenced when creating tasks with the `Host` instance. This allows for flexible job submission configurations based on the host's capabilities and requirements.\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "from pyflow import Suite, Task, SlurmHost\n",
    "# Create a suite with a local host\n",
    "suite = Suite(\n",
    "    \"example_suite\", \n",
    "    host=SlurmHost(\n",
    "        name=\"slurm_host\",\n",
    "        submit_arguments={\"simple_jobs\": {\"job_name\": \"%TASK%\", \"partition\": \"compute\", \"time\": \"01:00:00\"}}\n",
    "        workdir=\"$JOBSWDIR\",\n",
    "    ),\n",
    ")\n",
    "with suite:\n",
    "    # Add a task to the suite\n",
    "    Task(\"example_task\", script=\"echo 'Hello, World!'\", submit_arguments=\"simple_jobs\")\n",
    "```\n",
    "The above code will generate a task that runs the command `echo 'Hello, World!'` on a SLURM-managed host. The task will be submitted with the specified job name, partition, and time limit. The generated script will look something like this:\n",
    "\n",
    "```bash (title=\"example_task.ecf\")\n",
    "#!/bin/bash\n",
    "# This file is generated by pyflow\n",
    "# SBATCH --partition=compute\n",
    "# SBATCH --time=01:00:00\n",
    "# SBATCH --job-name=%TASK%\n",
    "\n",
    "[[ -d \"$JOBSWDIR\" ]] || mkdir -p \"$JOBSWDIR\"\n",
    "cd \"$JOBSWDIR\"\n",
    "echo \"Current working directory: $(pwd)\"\n",
    "\n",
    "%nopp\n",
    "echo 'Hello, World!'\n",
    "(...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04b3be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
